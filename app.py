# app.py
from __future__ import annotations

import time
import urllib.request
from io import BytesIO
from typing import Dict, List, Tuple, Literal

import numpy as np
import pandas as pd
import streamlit as st
import yfinance as yf

# =========================
# 1. ã‚¢ãƒ—ãƒªè¨­å®š & èªè¨¼
# =========================
st.set_page_config(page_title="äºŒæ®µä¸Šã’ã‚¹ã‚­ãƒ£ãƒŠãƒ¼", layout="wide")
MY_PASSWORD = "stock testa"  # â€»è¦æœ›ã«ã‚ˆã‚Šç›´æ›¸ãã®ã¾ã¾

if "auth" not in st.session_state:
    st.session_state.auth = False

if not st.session_state.auth:
    st.title("ğŸ”’ èªè¨¼")
    pwd = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password")
    if pwd == MY_PASSWORD:
        st.session_state.auth = True
        st.rerun()
    st.stop()

# =========================
# 2. ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
# =========================
st.sidebar.title("âš™ï¸ ã‚¹ã‚­ãƒ£ãƒ³æ¡ä»¶")

GITHUB_CSV_URL = "https://raw.githubusercontent.com/watarai0202-netizen/stocktest-app-1/main/data_j.csv"
target_market = st.sidebar.radio("ğŸ“Š å¸‚å ´é¸æŠ", ("ã‚°ãƒ­ãƒ¼ã‚¹", "ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰", "ãƒ—ãƒ©ã‚¤ãƒ "), index=0)

st.sidebar.subheader("ğŸš« ä¸äººæ°—ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼")
min_avg_value = st.sidebar.slider("æœ€ä½å£²è²·ä»£é‡‘(5æ—¥å¹³å‡/å„„å††)", 0.05, 20.0, 0.5, 0.05)

st.sidebar.subheader("ğŸ“ˆ äºŒæ®µä¸Šã’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆä»•è¾¼ã¿é–‹å§‹ã‚·ã‚°ãƒŠãƒ«ï¼‰")
jump_days = st.sidebar.selectbox("1. ç¬¬ä¸€æ³¢ã®ç´¯ç©æ—¥æ•°", [2, 3, 4, 5], index=1)
# ã“ã“ã¯â€œå³ã—ã™ãå•é¡Œâ€ãŒèµ·ãã‚„ã™ã„ã®ã§ä¸‹é™ã‚’ä½ã‚ã«ã—ã¦ãŠã
min_jump = st.sidebar.slider(f"2. éå»40æ—¥ã®æœ€å¤§{jump_days}æ—¥ä¸Šæ˜‡ç‡(%)", 5, 80, 15, 1)

vol_dry_limit = st.sidebar.slider("3. å‡ºæ¥é«˜æ¯æ¸‡åº¦ï¼ˆå½“æ—¥/20æ—¥ä¸­å¤®å€¤ï¼‰ä¸Šé™", 0.05, 2.0, 0.65, 0.05)
ma_near_pct = st.sidebar.slider("4. 25æ—¥ç·šã¨ã®ä¹–é›¢(Â±%)", 0.5, 15.0, 3.0, 0.1)

atr_contract_limit = st.sidebar.slider("5. ATRåç¸®ï¼ˆATR5/ATR20ï¼‰ä¸Šé™", 0.3, 1.5, 0.90, 0.05)
dist_to_high_limit = st.sidebar.slider("6. 20æ—¥é«˜å€¤ã¾ã§ã®è·é›¢(%) ä¸Šé™", 0.5, 15.0, 5.0, 0.1)

require_ma_up = st.sidebar.checkbox("7. 25MAãŒä¸Šå‘ãï¼ˆ5æ—¥å‰æ¯”+ï¼‰ã‚’å¿…é ˆ", value=False)

st.sidebar.subheader("ğŸ§ª å®Ÿè¡Œè¨­å®š")
batch_size = st.sidebar.slider("ãƒãƒƒãƒã‚µã‚¤ã‚ºï¼ˆyfinanceä¸€æ‹¬å–å¾—ï¼‰", 10, 100, 50, 5)
use_auto_adjust = st.sidebar.checkbox("ä¾¡æ ¼ã‚’èª¿æ•´ï¼ˆauto_adjust=Trueï¼‰", value=True)
scan_period = st.sidebar.selectbox("ã‚¹ã‚­ãƒ£ãƒ³ç”¨ å–å¾—æœŸé–“", ["3mo", "6mo", "1y"], index=1)

st.sidebar.subheader("ğŸ§ª è»½é‡æ¤œè¨¼ï¼ˆç›´è¿‘ã ã‘ï¼‰")
enable_validate = st.sidebar.checkbox("ç›´è¿‘Nå–¶æ¥­æ—¥ã ã‘æ¤œè¨¼ã™ã‚‹ï¼ˆè»½é‡ï¼‰", value=True)
validate_days = st.sidebar.slider("æ¤œè¨¼å¯¾è±¡ï¼šç›´è¿‘Nå–¶æ¥­æ—¥", 40, 200, 120, 10)
validate_horizon = st.sidebar.selectbox("å°†æ¥ã®è©•ä¾¡æœŸé–“ï¼ˆkå–¶æ¥­æ—¥ï¼‰", [3, 5, 10, 15, 20], index=1)
validate_hit = st.sidebar.slider("å‘½ä¸­åˆ¤å®šï¼ˆkæ—¥å†… æœ€å¤§ä¸Šæ˜‡ãŒ +ä½•% ä»¥ä¸Šï¼‰", 3, 40, 10, 1)

# ç›´è¿‘æ¤œè¨¼ã®ã€Œã‚·ã‚°ãƒŠãƒ«å®šç¾©ã€ã‚’é¸ã¹ã‚‹ã‚ˆã†ã«ã™ã‚‹
# ANDæ¡ä»¶ã¯å³ã—ã‚ã§ä»¶æ•°ãŒå°‘ãªããªã‚Šã‚„ã™ã„ã®ã§ã€ã‚¹ã‚³ã‚¢ä¸Šä½%ã‚‚ç”¨æ„
signal_mode: Literal["ANDæ¡ä»¶", "ã‚¹ã‚³ã‚¢ä¸Šä½%"] = st.sidebar.radio(
    "æ¤œè¨¼ã§ã®ã‚·ã‚°ãƒŠãƒ«å®šç¾©",
    ["ANDæ¡ä»¶", "ã‚¹ã‚³ã‚¢ä¸Šä½%"],
    index=1,
)
score_top_pct = st.sidebar.slider("ï¼ˆã‚¹ã‚³ã‚¢ä¸Šä½% ã®å ´åˆï¼‰ä¸Šä½ä½•%ã‚’ã‚·ã‚°ãƒŠãƒ«ã«ã™ã‚‹ï¼Ÿ", 1, 20, 5, 1)

if st.sidebar.button("ğŸ”„ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢"):
    st.cache_data.clear()
    st.rerun()

# =========================
# 3. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ & æŒ‡æ¨™
# =========================
@st.cache_data(ttl=3600)
def load_master_data(market_name: str) -> Tuple[List[str], Dict[str, str]]:
    with urllib.request.urlopen(GITHUB_CSV_URL) as resp:
        df = pd.read_csv(BytesIO(resp.read()))

    m_key = f"{market_name}ï¼ˆå†…å›½æ ªå¼ï¼‰"
    df_filtered = df[(df["å¸‚å ´ãƒ»å•†å“åŒºåˆ†"] == m_key) & (df["33æ¥­ç¨®åŒºåˆ†"] != "ï¼")].copy()

    tickers = [f"{str(code).split('.')[0]}.T" for code in df_filtered["ã‚³ãƒ¼ãƒ‰"]]
    info = {f"{str(row['ã‚³ãƒ¼ãƒ‰']).split('.')[0]}.T": row["éŠ˜æŸ„å"] for _, row in df_filtered.iterrows()}
    return tickers, info


def _normalize_ohlcv(df: pd.DataFrame) -> pd.DataFrame:
    if df is None or df.empty:
        return pd.DataFrame()

    # MultiIndex å¯¾ç­–
    if isinstance(df.columns, pd.MultiIndex):
        df.columns = df.columns.get_level_values(-1)

    df = df.copy()
    if "Close" not in df.columns:
        if "Adj Close" in df.columns:
            df["Close"] = df["Adj Close"]
        else:
            return pd.DataFrame()

    df = df.dropna(subset=["Close"]).sort_index()
    if df.empty:
        return pd.DataFrame()

    # æ¬ ã‘ã‚„ã™ã„åˆ—ã®è£œå®Œ
    for col in ["Open", "High", "Low"]:
        if col not in df.columns:
            df[col] = df["Close"]
        else:
            df[col] = df[col].fillna(df["Close"])

    if "Volume" not in df.columns:
        df["Volume"] = 0
    else:
        df["Volume"] = df["Volume"].fillna(0)

    for col in ["Open", "High", "Low", "Close", "Volume"]:
        df[col] = pd.to_numeric(df[col], errors="coerce")

    df = df.dropna(subset=["Close"])
    return df


def fetch_ohlcv(ticker: str, period: str, auto_adjust: bool) -> pd.DataFrame:
    df = yf.download(
        ticker,
        period=period,
        interval="1d",
        progress=False,
        auto_adjust=auto_adjust,
    )
    return _normalize_ohlcv(df)


def compute_atr(df: pd.DataFrame, period: int) -> pd.Series:
    high = df["High"].astype(float)
    low = df["Low"].astype(float)
    close = df["Close"].astype(float)
    prev_close = close.shift(1)

    tr = pd.concat(
        [(high - low).abs(), (high - prev_close).abs(), (low - prev_close).abs()],
        axis=1,
    ).max(axis=1)

    return tr.rolling(period).mean()


def check_strategy_lastbar(
    data: pd.DataFrame,
    *,
    min_avg_value_: float,
    jump_days_: int,
    min_jump_: float,
    vol_dry_limit_: float,
    ma_near_pct_: float,
    atr_contract_limit_: float,
    dist_to_high_limit_: float,
    require_ma_up_: bool,
) -> Tuple[bool, str, Dict[str, float]]:
    """
    ä»Šæ—¥ï¼ˆæœ€æ–°è¶³ï¼‰ãŒã€Œä»•è¾¼ã¿é–‹å§‹å€™è£œã€ã‹ã©ã†ã‹åˆ¤å®š
    """
    need_len = max(70, 25 + 10, 40 + jump_days_ + 5)
    if len(data) < need_len:
        return False, "ãƒ‡ãƒ¼ã‚¿ä¸è¶³", {}

    c = data["Close"].astype(float)
    v = data["Volume"].astype(float)

    # å£²è²·ä»£é‡‘ï¼ˆç›´è¿‘5æ—¥å¹³å‡/å„„å††ï¼‰
    avg_val = (c * v).tail(5).mean() / 1e8
    if avg_val < min_avg_value_:
        return False, "å£²è²·ä»£é‡‘ä¸è¶³", {"avg_val": float(avg_val)}

    # ç¬¬ä¸€æ³¢ï¼šéå»40æ—¥ã§æœ€å¤§Næ—¥ä¸Šæ˜‡ç‡
    jump_series = (c / c.shift(jump_days_) - 1.0) * 100.0
    max_jump = jump_series.tail(40).max()
    if pd.isna(max_jump) or max_jump < min_jump_:
        return False, "ç¬¬ä¸€æ³¢å¼±ã„", {"max_jump": float(max_jump) if pd.notna(max_jump) else 0.0}

    # æ¯æ¸‡ï¼šå½“æ—¥/20æ—¥ä¸­å¤®å€¤
    v_med20 = v.tail(20).median()
    rvol_med = (v.iloc[-1] / v_med20) if v_med20 > 0 else 9.9
    if rvol_med > vol_dry_limit_:
        return False, "æ¯æ¸‡ã—ã¦ãªã„", {"rvol": float(rvol_med)}

    # 25MAä¹–é›¢
    ma25 = c.rolling(25).mean().iloc[-1]
    curr_p = c.iloc[-1]
    diff_ma25 = abs(curr_p - ma25) / ma25 * 100.0
    if diff_ma25 > ma_near_pct_:
        return False, "25MAä¹–é›¢å¤§", {"diff_ma25": float(diff_ma25)}

    # ATRåç¸®
    atr5 = compute_atr(data, 5).iloc[-1]
    atr20 = compute_atr(data, 20).iloc[-1]
    atr_ratio = (atr5 / atr20) if atr20 and atr20 > 0 else 9.9
    if atr_ratio > atr_contract_limit_:
        return False, "ãƒœãƒ©åç¸®å¼±ã„", {"atr_ratio": float(atr_ratio)}

    # é«˜å€¤è·é›¢ï¼ˆ20æ—¥ï¼‰
    high20 = c.tail(20).max()
    dist_to_high = (high20 - curr_p) / curr_p * 100.0
    if dist_to_high > dist_to_high_limit_:
        return False, "é«˜å€¤ã¾ã§é ã„", {"dist_to_high": float(dist_to_high)}

    # MAã®å‘ã
    ma25_now = c.rolling(25).mean().iloc[-1]
    ma25_prev = c.rolling(25).mean().shift(5).iloc[-1]
    ma25_slope = ma25_now - ma25_prev
    if require_ma_up_ and not (ma25_slope > 0):
        return False, "MAä¸‹å‘ã", {"ma25_slope": float(ma25_slope)}

    metrics = {
        "avg_val": float(avg_val),
        "max_jump": float(max_jump),
        "rvol": float(rvol_med),
        "diff_ma25": float(diff_ma25),
        "atr_ratio": float(atr_ratio),
        "dist_to_high": float(dist_to_high),
        "ma25_slope": float(ma25_slope),
        "price": float(curr_p),
    }
    return True, "OK", metrics


def score_metrics(m: Dict[str, float]) -> float:
    """
    å€™è£œã®å„ªå…ˆé †ä½ç”¨ï¼ˆå¤§ãã„ã»ã©â€œäºŒæ®µä¸Šã’ã£ã½ã„â€ï¼‰
    """
    max_jump = max(0.0, min(m.get("max_jump", 0.0), 200.0))
    rvol = max(0.01, min(m.get("rvol", 9.9), 9.9))
    atr_ratio = max(0.01, min(m.get("atr_ratio", 9.9), 9.9))
    dist = max(0.0, min(m.get("dist_to_high", 99.0), 99.0))
    diff = max(0.0, min(m.get("diff_ma25", 99.0), 99.0))
    slope = m.get("ma25_slope", 0.0)

    s_jump = max_jump / 80.0
    s_rvol = 1.0 / rvol
    s_atr = 1.0 / atr_ratio
    s_dist = 1.0 / (1.0 + dist)
    s_diff = 1.0 / (1.0 + diff)
    s_slope = 0.15 if slope > 0 else 0.0

    return (
        1.30 * s_jump +
        1.10 * s_rvol +
        1.10 * s_atr +
        0.90 * s_dist +
        0.70 * s_diff +
        s_slope
    )


def score_series(df: pd.DataFrame, *, jump_days_: int, min_avg_value_: float) -> pd.Series:
    """
    å„æ—¥ã‚¹ã‚³ã‚¢ï¼ˆæ¤œè¨¼ç”¨ï¼‰
    """
    c = df["Close"].astype(float)
    v = df["Volume"].astype(float)

    jump = (c / c.shift(jump_days_) - 1.0) * 100.0
    max_jump_40 = jump.rolling(40).max().clip(lower=0)

    v_med20 = v.rolling(20).median()
    rvol_med = (v / v_med20).replace([np.inf, -np.inf], np.nan)

    ma25 = c.rolling(25).mean()
    diff_ma25 = ((c - ma25).abs() / ma25 * 100.0).replace([np.inf, -np.inf], np.nan)

    atr5 = compute_atr(df, 5)
    atr20 = compute_atr(df, 20)
    atr_ratio = (atr5 / atr20).replace([np.inf, -np.inf], np.nan)

    high20 = c.rolling(20).max()
    dist_to_high = ((high20 - c) / c * 100.0).replace([np.inf, -np.inf], np.nan)

    avg_val = (c * v).rolling(5).mean() / 1e8

    s_jump = (max_jump_40 / 80.0).clip(upper=3.0)
    s_rvol = (1.0 / rvol_med.clip(lower=0.05)).clip(upper=10.0)
    s_atr  = (1.0 / atr_ratio.clip(lower=0.20)).clip(upper=10.0)
    s_dist = (1.0 / (1.0 + dist_to_high.clip(lower=0.0))).clip(upper=1.0)
    s_diff = (1.0 / (1.0 + diff_ma25.clip(lower=0.0))).clip(upper=1.0)

    ma25_slope = ma25 - ma25.shift(5)
    s_slope = (ma25_slope > 0).astype(float) * 0.15

    score = (
        1.30 * s_jump +
        1.10 * s_rvol +
        1.10 * s_atr +
        0.90 * s_dist +
        0.70 * s_diff +
        s_slope
    )

    # æµå‹•æ€§ãŒä½ã™ãã‚‹æ—¥ã¯ç„¡åŠ¹
    score = score.where(avg_val >= min_avg_value_)
    return score


def signal_series_and(
    df: pd.DataFrame,
    *,
    min_avg_value_: float,
    jump_days_: int,
    min_jump_: float,
    vol_dry_limit_: float,
    ma_near_pct_: float,
    atr_contract_limit_: float,
    dist_to_high_limit_: float,
    require_ma_up_: bool,
) -> pd.Series:
    """
    éå»ã«ã‚‚åŒã˜æ¡ä»¶ã‚’å½“ã¦ã¦ã€Œãã®æ—¥ã‚·ã‚°ãƒŠãƒ«ã ã£ãŸã‹ã€ã‚’ True/False ã§è¿”ã™ï¼ˆæ¤œè¨¼ç”¨ï¼‰
    """
    c = df["Close"].astype(float)
    v = df["Volume"].astype(float)

    avg_val = (c * v).rolling(5).mean() / 1e8

    jump = (c / c.shift(jump_days_) - 1.0) * 100.0
    max_jump_40 = jump.rolling(40).max()

    v_med20 = v.rolling(20).median()
    rvol_med = v / v_med20

    ma25 = c.rolling(25).mean()
    diff_ma25 = (c - ma25).abs() / ma25 * 100.0

    atr5 = compute_atr(df, 5)
    atr20 = compute_atr(df, 20)
    atr_ratio = atr5 / atr20

    high20 = c.rolling(20).max()
    dist_to_high = (high20 - c) / c * 100.0

    ma25_slope = ma25 - ma25.shift(5)

    cond = (
        (avg_val >= min_avg_value_) &
        (max_jump_40 >= min_jump_) &
        (rvol_med <= vol_dry_limit_) &
        (diff_ma25 <= ma_near_pct_) &
        (atr_ratio <= atr_contract_limit_) &
        (dist_to_high <= dist_to_high_limit_)
    )
    if require_ma_up_:
        cond = cond & (ma25_slope > 0)

    return cond.fillna(False)


def validate_recent(
    tickers: List[str],
    info_db: Dict[str, str],
    *,
    auto_adjust: bool,
    recent_days: int,
    horizon: int,
    hit_threshold: float,
    mode: Literal["ANDæ¡ä»¶", "ã‚¹ã‚³ã‚¢ä¸Šä½%"],
    score_top_pct_: int,
    # ANDæ¡ä»¶ç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    min_avg_value_: float,
    jump_days_: int,
    min_jump_: float,
    vol_dry_limit_: float,
    ma_near_pct_: float,
    atr_contract_limit_: float,
    dist_to_high_limit_: float,
    require_ma_up_: bool,
) -> Tuple[pd.DataFrame, pd.DataFrame, Dict[str, float]]:

    per_ticker_rows = []
    trade_rows = []

    total_signals = 0
    total_hits = 0

    for t in tickers:
        # âœ… ã¾ãšã¯ååˆ†é•·ãå–ã‚‹ï¼ˆæŒ‡æ¨™è¨ˆç®—ç”¨ï¼‰
        df_full = fetch_ohlcv(t, period="1y", auto_adjust=auto_adjust)
        if df_full.empty or len(df_full) < 120:
            per_ticker_rows.append(
                {"ã‚³ãƒ¼ãƒ‰": t.replace(".T", ""), "éŠ˜æŸ„å": info_db.get(t, "ä¸æ˜"), "signals": 0,
                 "hit_rate_%": np.nan, "med_max_up_%": np.nan, "worst_dd_%": np.nan}
            )
            continue

        # âœ… ã‚·ã‚°ãƒŠãƒ«ã¯ â€œå…¨æœŸé–“â€ ã§è¨ˆç®—ï¼ˆrollingã®ãŸã‚ï¼‰
        if mode == "ANDæ¡ä»¶":
            sig_full = signal_series_and(
                df_full,
                min_avg_value_=min_avg_value_,
                jump_days_=jump_days_,
                min_jump_=min_jump_,
                vol_dry_limit_=vol_dry_limit_,
                ma_near_pct_=ma_near_pct_,
                atr_contract_limit_=atr_contract_limit_,
                dist_to_high_limit_=dist_to_high_limit_,
                require_ma_up_=require_ma_up_,
            )
        else:
            sc = score_series(df_full, jump_days_=jump_days_, min_avg_value_=min_avg_value_)
            sc_valid = sc.dropna()
            if sc_valid.empty:
                sig_full = pd.Series(False, index=df_full.index)
            else:
                q = 1.0 - (score_top_pct_ / 100.0)  # ä¸Šä½5%ãªã‚‰0.95
                thr = sc_valid.quantile(q)
                sig_full = (sc >= thr).fillna(False)

        sig_full = sig_full.reindex(df_full.index).fillna(False)

        # âœ… â€œç›´è¿‘Næ—¥â€ ã®æ¤œè¨¼çª“ã ã‘åˆ‡ã‚Šå‡ºã™ï¼ˆfuture horizon ãŒè¦‹ã‚Œã‚‹ç¯„å›²ï¼‰
        if len(df_full) <= (recent_days + horizon + 5):
            # ãƒ‡ãƒ¼ã‚¿ãŒçŸ­ã„å ´åˆã¯å¯èƒ½ãªç¯„å›²ã§
            start = 0
        else:
            start = len(df_full) - (recent_days + horizon)

        end = len(df_full) - horizon  # æœ€å¾Œã®horizonæ—¥ã¯æœªæ¥ãŒç„¡ã„ã®ã§é™¤å¤–
        window_idx = df_full.index[start:end]

        sig = sig_full.loc[window_idx]
        if sig.sum() == 0:
            per_ticker_rows.append(
                {"ã‚³ãƒ¼ãƒ‰": t.replace(".T", ""), "éŠ˜æŸ„å": info_db.get(t, "ä¸æ˜"), "signals": 0,
                 "hit_rate_%": np.nan, "med_max_up_%": np.nan, "worst_dd_%": np.nan}
            )
            continue

        # ---- æœªæ¥kæ—¥ã‚’è©•ä¾¡ ----
        c = df_full["Close"].astype(float).to_numpy()
        h = df_full["High"].astype(float).to_numpy()
        l = df_full["Low"].astype(float).to_numpy()

        idx_map = {idx: i for i, idx in enumerate(df_full.index)}
        sig_dates = sig[sig].index.tolist()

        max_ups = []
        max_dds = []
        hits = 0

        for d in sig_dates:
            i = idx_map.get(d)
            if i is None or i + 1 >= len(df_full):
                continue

            end_i = min(len(df_full), i + 1 + horizon)
            base = c[i]
            if not np.isfinite(base) or base <= 0:
                continue

            max_high = np.nanmax(h[i + 1:end_i])
            min_low = np.nanmin(l[i + 1:end_i])

            max_up = (max_high / base - 1.0) * 100.0 if np.isfinite(max_high) else np.nan
            max_dd = (min_low / base - 1.0) * 100.0 if np.isfinite(min_low) else np.nan

            if np.isfinite(max_up):
                max_ups.append(float(max_up))
            if np.isfinite(max_dd):
                max_dds.append(float(max_dd))

            hit = (np.isfinite(max_up) and (max_up >= hit_threshold))
            hits += int(hit)

            trade_rows.append(
                {
                    "date": d,
                    "ã‚³ãƒ¼ãƒ‰": t.replace(".T", ""),
                    "éŠ˜æŸ„å": info_db.get(t, "ä¸æ˜"),
                    "base_close": float(base),
                    "max_up_%": float(max_up) if np.isfinite(max_up) else np.nan,
                    "max_dd_%": float(max_dd) if np.isfinite(max_dd) else np.nan,
                    "hit": bool(hit),
                }
            )

        signals = len(sig_dates)
        hit_rate = (hits / signals * 100.0) if signals else np.nan

        per_ticker_rows.append(
            {
                "ã‚³ãƒ¼ãƒ‰": t.replace(".T", ""),
                "éŠ˜æŸ„å": info_db.get(t, "ä¸æ˜"),
                "signals": int(signals),
                "hit_rate_%": float(hit_rate) if np.isfinite(hit_rate) else np.nan,
                "med_max_up_%": float(np.nanmedian(max_ups)) if max_ups else np.nan,
                "worst_dd_%": float(np.nanmin(max_dds)) if max_dds else np.nan,
            }
        )

        total_signals += signals
        total_hits += hits

    per_df = pd.DataFrame(per_ticker_rows)
    trades_df = pd.DataFrame(trade_rows)

    overall = {
        "total_signals": float(total_signals),
        "total_hit_rate_%": float((total_hits / total_signals * 100.0) if total_signals else np.nan),
        "overall_med_max_up_%": float(np.nanmedian(trades_df["max_up_%"])) if not trades_df.empty else np.nan,
        "overall_worst_dd_%": float(np.nanmin(trades_df["max_dd_%"])) if not trades_df.empty else np.nan,
    }
    return per_df, trades_df, overall



# =========================
# 4. ãƒ¡ã‚¤ãƒ³ç”»é¢
# =========================
st.title(f"ğŸš€ {target_market}ãƒ»äºŒæ®µä¸Šã’ç‹™ã„ï¼ˆä»•è¾¼ã¿é–‹å§‹ï¼‰")
st.caption("ç¬¬ä¸€æ³¢â†’å‡ºæ¥é«˜æ¯æ¸‡â†’25MAä»˜è¿‘â†’ATRåç¸®â†’é«˜å€¤ãŒè¿‘ã„ã€ã§â€œçŸ­æœŸå†å™´ç«â€å€™è£œã‚’æŠ½å‡ºã€‚")

colA, colB, colC = st.columns([1.2, 1.2, 1.8])
with colA:
    st.write("**ã‚¹ã‚­ãƒ£ãƒ³å¯¾è±¡**")
    st.write(f"- å¸‚å ´: {target_market}")
    st.write(f"- å–å¾—æœŸé–“: {scan_period} / 1d")

with colB:
    st.write("**ä¸»è¦æ¡ä»¶ï¼ˆä»Šæ—¥ã®å€™è£œæŠ½å‡ºï¼‰**")
    st.write(f"- å£²è²·ä»£é‡‘: {min_avg_value:.2f}å„„/æ—¥ä»¥ä¸Š")
    st.write(f"- ç¬¬ä¸€æ³¢: {jump_days}æ—¥ã§{min_jump:.0f}%ä»¥ä¸Š")
    st.write(f"- æ¯æ¸‡: RVOL(ä¸­å¤®å€¤)â‰¤{vol_dry_limit:.2f}")

with colC:
    st.write("**ãƒˆãƒªã‚¬ãƒ¼å¯„ã›**")
    st.write(f"- 25MAä¹–é›¢â‰¤{ma_near_pct:.1f}% / ATR5/20â‰¤{atr_contract_limit:.2f} / é«˜å€¤è·é›¢â‰¤{dist_to_high_limit:.1f}%")
    st.write(f"- 25MAä¸Šå‘ãå¿…é ˆ: {'ON' if require_ma_up else 'OFF'}")

if st.button("ğŸ“¡ ã‚¹ã‚­ãƒ£ãƒ³é–‹å§‹", type="primary"):
    tickers, info_db = load_master_data(target_market)
    if not tickers:
        st.warning("å¯¾è±¡éŠ˜æŸ„ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        st.stop()

    results: List[Dict[str, object]] = []
    fail_reasons: Dict[str, int] = {}
    fetch_fail: List[str] = []

    progress_bar = st.progress(0.0)
    status_text = st.empty()

    total = len(tickers)
    t0 = time.time()

    for i in range(0, total, batch_size):
        batch = tickers[i: i + batch_size]
        status_text.text(f"ã‚¹ã‚­ãƒ£ãƒ³ä¸­... {i}/{total}")
        progress_bar.progress(min(1.0, i / total))

        try:
            df_batch = yf.download(
                batch,
                period=scan_period,
                interval="1d",
                progress=False,
                group_by="ticker",
                threads=True,
                auto_adjust=use_auto_adjust,
            )

            # 1éŠ˜æŸ„ã®ã¨ã
            if not isinstance(df_batch.columns, pd.MultiIndex):
                df_batch = pd.concat({batch[0]: df_batch}, axis=1)

            tickers_in_batch = set(df_batch.columns.get_level_values(0))

            for t in batch:
                if t not in tickers_in_batch:
                    fetch_fail.append(t)
                    continue

                stock_data = _normalize_ohlcv(df_batch[t])
                need_cols = {"Open", "High", "Low", "Close", "Volume"}
                if stock_data.empty or not need_cols.issubset(set(stock_data.columns)):
                    fetch_fail.append(t)
                    continue

                ok, reason, m = check_strategy_lastbar(
                    stock_data,
                    min_avg_value_=min_avg_value,
                    jump_days_=jump_days,
                    min_jump_=min_jump,
                    vol_dry_limit_=vol_dry_limit,
                    ma_near_pct_=ma_near_pct,
                    atr_contract_limit_=atr_contract_limit,
                    dist_to_high_limit_=dist_to_high_limit,
                    require_ma_up_=require_ma_up,
                )
                if not ok:
                    fail_reasons[reason] = fail_reasons.get(reason, 0) + 1
                    continue

                sc = score_metrics(m)
                results.append(
                    {
                        "ticker": t,
                        "ã‚³ãƒ¼ãƒ‰": t.replace(".T", ""),
                        "éŠ˜æŸ„å": info_db.get(t, "ä¸æ˜"),
                        "ã‚¹ã‚³ã‚¢": float(sc),
                        "ç¾åœ¨å€¤": float(m["price"]),
                        f"ç¬¬ä¸€æ³¢({jump_days}æ—¥)%": float(m["max_jump"]),
                        "æ¯æ¸‡RVOL(ä¸­å¤®å€¤)": float(m["rvol"]),
                        "25MAä¹–é›¢%": float(m["diff_ma25"]),
                        "ATR5/20": float(m["atr_ratio"]),
                        "é«˜å€¤è·é›¢%": float(m["dist_to_high"]),
                        "ä»£é‡‘(å„„å††)": float(m["avg_val"]),
                    }
                )

        except Exception:
            fetch_fail.extend(batch)
            continue

    progress_bar.progress(1.0)
    status_text.empty()
    elapsed = time.time() - t0

    # ---- ã‚µãƒãƒªãƒ¼ ----
    st.subheader("çµæœã‚µãƒãƒªãƒ¼")
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("ãƒ’ãƒƒãƒˆéŠ˜æŸ„æ•°", f"{len(results)}")
    c2.metric("å¯¾è±¡éŠ˜æŸ„æ•°", f"{total}")
    c3.metric("å–å¾—å¤±æ•—æ•°", f"{len(fetch_fail)}")
    c4.metric("å‡¦ç†æ™‚é–“(ç§’)", f"{elapsed:.1f}")

    if fail_reasons:
        with st.expander("è½é¸ç†ç”±ã®å†…è¨³ï¼ˆãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ï¼‰", expanded=False):
            reason_df = pd.DataFrame(
                [{"ç†ç”±": k, "ä»¶æ•°": v} for k, v in sorted(fail_reasons.items(), key=lambda x: -x[1])]
            )
            st.dataframe(reason_df, use_container_width=True, hide_index=True)

    if fetch_fail:
        with st.expander("å–å¾—å¤±æ•—ãƒ†ã‚£ãƒƒã‚«ãƒ¼ï¼ˆyfinanceæ¬ æãªã©ï¼‰", expanded=False):
            st.write(", ".join(fetch_fail[:300]) + (" ..." if len(fetch_fail) > 300 else ""))

    if not results:
        st.warning("è©²å½“éŠ˜æŸ„ãªã—ã€‚ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç·©ã‚ã¦ãã ã•ã„ï¼ˆç‰¹ã« ç¬¬ä¸€æ³¢/æ¯æ¸‡/25MAä¹–é›¢ ãŒåŠ¹ãã¾ã™ï¼‰ã€‚")
        st.stop()

    # ---- çµæœè¡¨ç¤º ----
    st.success(f"ğŸ¯ {len(results)} éŠ˜æŸ„ãŒæ¡ä»¶ã«åˆè‡´ã—ã¾ã—ãŸï¼ˆã‚¹ã‚³ã‚¢é †ï¼‰")
    res_df = pd.DataFrame(results).sort_values("ã‚¹ã‚³ã‚¢", ascending=False).reset_index(drop=True)

    show_df = res_df.drop(columns=["ticker"]).copy()
    show_df["ã‚¹ã‚³ã‚¢"] = show_df["ã‚¹ã‚³ã‚¢"].map(lambda x: f"{x:.3f}")
    show_df["ç¾åœ¨å€¤"] = show_df["ç¾åœ¨å€¤"].map(lambda x: f"{x:,.1f}")
    show_df[f"ç¬¬ä¸€æ³¢({jump_days}æ—¥)%"] = show_df[f"ç¬¬ä¸€æ³¢({jump_days}æ—¥)%"].map(lambda x: f"{x:.1f}%")
    show_df["æ¯æ¸‡RVOL(ä¸­å¤®å€¤)"] = show_df["æ¯æ¸‡RVOL(ä¸­å¤®å€¤)"].map(lambda x: f"{x:.2f}å€")
    show_df["25MAä¹–é›¢%"] = show_df["25MAä¹–é›¢%"].map(lambda x: f"{x:.1f}%")
    show_df["ATR5/20"] = show_df["ATR5/20"].map(lambda x: f"{x:.2f}")
    show_df["é«˜å€¤è·é›¢%"] = show_df["é«˜å€¤è·é›¢%"].map(lambda x: f"{x:.1f}%")
    show_df["ä»£é‡‘(å„„å††)"] = show_df["ä»£é‡‘(å„„å††)"].map(lambda x: f"{x:.2f}å„„å††")

    st.dataframe(show_df, use_container_width=True, hide_index=True)

    # =========================
    # ç›´è¿‘ã ã‘æ¤œè¨¼ï¼ˆè»½é‡ï¼‰
    # =========================
    if enable_validate:
        st.subheader("ğŸ§ª ç›´è¿‘ã ã‘æ¤œè¨¼ï¼ˆè»½é‡ï¼‰")
        st.write(
            f"- å¯¾è±¡ï¼šä»Šå›ãƒ’ãƒƒãƒˆã—ãŸéŠ˜æŸ„ï¼ˆ{len(res_df)}ä»¶ï¼‰\n"
            f"- æœŸé–“ï¼šç›´è¿‘ **{validate_days}å–¶æ¥­æ—¥**\n"
            f"- å…ˆèª­ã¿ï¼š**{validate_horizon}æ—¥**\n"
            f"- å‘½ä¸­ï¼šå…ˆèª­ã¿æœŸé–“å†…ã®æœ€å¤§ä¸Šæ˜‡ãŒ **+{validate_hit}%** ä»¥ä¸Š\n"
            f"- ã‚·ã‚°ãƒŠãƒ«å®šç¾©ï¼š**{signal_mode}**"
            + (f"ï¼ˆã‚¹ã‚³ã‚¢ä¸Šä½{score_top_pct}%ï¼‰" if signal_mode == "ã‚¹ã‚³ã‚¢ä¸Šä½%" else "")
        )

        with st.spinner("ç›´è¿‘æ¤œè¨¼ã‚’è¨ˆç®—ä¸­ï¼ˆè»½é‡ï¼‰..."):
            per_df, trades_df, overall = validate_recent(
                res_df["ticker"].tolist(),
                info_db,
                auto_adjust=use_auto_adjust,
                recent_days=int(validate_days),
                horizon=int(validate_horizon),
                hit_threshold=float(validate_hit),
                mode=signal_mode,
                score_top_pct_=int(score_top_pct),
                min_avg_value_=min_avg_value,
                jump_days_=jump_days,
                min_jump_=min_jump,
                vol_dry_limit_=vol_dry_limit,
                ma_near_pct_=ma_near_pct,
                atr_contract_limit_=atr_contract_limit,
                dist_to_high_limit_=dist_to_high_limit,
                require_ma_up_=require_ma_up,
            )

        m1, m2, m3, m4 = st.columns(4)
        m1.metric("å…¨ã‚·ã‚°ãƒŠãƒ«æ•°", f"{int(overall['total_signals']) if np.isfinite(overall['total_signals']) else 0}")
        m2.metric("å…¨ä½“ å‘½ä¸­ç‡", "-" if not np.isfinite(overall["total_hit_rate_%"]) else f"{overall['total_hit_rate_%']:.1f}%")
        m3.metric("å…¨ä½“ ä¸­å¤®å€¤(MaxUp)", "-" if not np.isfinite(overall["overall_med_max_up_%"]) else f"{overall['overall_med_max_up_%']:.1f}%")
        m4.metric("å…¨ä½“ ãƒ¯ãƒ¼ã‚¹ãƒˆDD", "-" if not np.isfinite(overall["overall_worst_dd_%"]) else f"{overall['overall_worst_dd_%']:.1f}%")

        per_df2 = per_df.copy()
        per_df2["hit_rate_%"] = per_df2["hit_rate_%"].map(lambda x: "-" if pd.isna(x) else f"{x:.1f}%")
        per_df2["med_max_up_%"] = per_df2["med_max_up_%"].map(lambda x: "-" if pd.isna(x) else f"{x:.1f}%")
        per_df2["worst_dd_%"] = per_df2["worst_dd_%"].map(lambda x: "-" if pd.isna(x) else f"{x:.1f}%")
        per_df2 = per_df2.sort_values(["signals"], ascending=[False])

        st.write("**éŠ˜æŸ„åˆ¥ï¼ˆç›´è¿‘ã®ã¿ï¼‰**")
        st.dataframe(per_df2, use_container_width=True, hide_index=True)

        if not trades_df.empty:
            with st.expander("ã‚·ã‚°ãƒŠãƒ«æ˜ç´°ï¼ˆç›´è¿‘ã®ã¿ï¼‰", expanded=False):
                td = trades_df.copy()
                td["base_close"] = td["base_close"].map(lambda x: f"{x:,.1f}")
                td["max_up_%"] = td["max_up_%"].map(lambda x: "-" if pd.isna(x) else f"{x:.1f}%")
                td["max_dd_%"] = td["max_dd_%"].map(lambda x: "-" if pd.isna(x) else f"{x:.1f}%")
                st.dataframe(td[["date", "ã‚³ãƒ¼ãƒ‰", "éŠ˜æŸ„å", "base_close", "max_up_%", "max_dd_%", "hit"]],
                             use_container_width=True, hide_index=True)

    # =========================
    # ãƒãƒ£ãƒ¼ãƒˆç¢ºèªå°ç·š
    # =========================
    st.subheader("å€™è£œãƒãƒ£ãƒ¼ãƒˆï¼ˆãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯ç¢ºèªï¼‰")
    pick_code = st.selectbox("éŠ˜æŸ„ã‚’é¸æŠ", options=res_df["ã‚³ãƒ¼ãƒ‰"].tolist(), index=0)
    pick_ticker = f"{pick_code}.T"

    try:
        df_one = fetch_ohlcv(pick_ticker, period=scan_period, auto_adjust=use_auto_adjust)
        if len(df_one) >= 10:
            st.write(f"**{pick_code}ï¼š{info_db.get(pick_ticker, 'ä¸æ˜')}**")
            st.line_chart(df_one["Close"], height=260)
            st.bar_chart(df_one["Volume"], height=180)
        else:
            st.info("ãƒãƒ£ãƒ¼ãƒˆè¡¨ç¤ºã«ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    except Exception as e:
        st.warning(f"ãƒãƒ£ãƒ¼ãƒˆå–å¾—ã«å¤±æ•—: {e}")

else:
    st.info("å·¦ã®æ¡ä»¶ã‚’èª¿æ•´ã—ã¦ã€ŒğŸ“¡ ã‚¹ã‚­ãƒ£ãƒ³é–‹å§‹ã€ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
