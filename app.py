# app.py
from __future__ import annotations

import time
import urllib.request
from io import BytesIO
from typing import Dict, List, Tuple

import pandas as pd
import streamlit as st
import yfinance as yf

# =========================
# 1. ã‚¢ãƒ—ãƒªè¨­å®š & èªè¨¼
# =========================
st.set_page_config(page_title="äºŒæ®µä¸Šã’ã‚¹ã‚­ãƒ£ãƒŠãƒ¼", layout="wide")
MY_PASSWORD = "stock testa"  # â€»è¦æœ›ã«ã‚ˆã‚Šç›´æ›¸ãã®ã¾ã¾

if "auth" not in st.session_state:
    st.session_state.auth = False

if not st.session_state.auth:
    st.title("ğŸ”’ èªè¨¼")
    pwd = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password")
    if pwd == MY_PASSWORD:
        st.session_state.auth = True
        st.rerun()
    st.stop()

# =========================
# 2. ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®šï¼ˆæ¡ä»¶æŒ‡å®šï¼‰
# =========================
st.sidebar.title("âš™ï¸ ã‚¹ã‚­ãƒ£ãƒ³æ¡ä»¶")

GITHUB_CSV_URL = "https://raw.githubusercontent.com/watarai0202-netizen/stocktest-app-1/main/data_j.csv"

target_market = st.sidebar.radio("ğŸ“Š å¸‚å ´é¸æŠ", ("ã‚°ãƒ­ãƒ¼ã‚¹", "ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰", "ãƒ—ãƒ©ã‚¤ãƒ "), index=0)

st.sidebar.subheader("ğŸš« ä¸äººæ°—ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼")
min_avg_value = st.sidebar.slider("æœ€ä½å£²è²·ä»£é‡‘(5æ—¥å¹³å‡/å„„å††)", 0.1, 10.0, 0.5, 0.1)

st.sidebar.subheader("ğŸ“ˆ äºŒæ®µä¸Šã’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆç²¾åº¦UPç‰ˆï¼‰")
# â‘  ç¬¬ä¸€æ³¢ï¼ˆè¤‡æ•°æ—¥ï¼‰ä¸Šæ˜‡ï¼š3æ—¥ç´¯ç©æœ€å¤§ä¸Šæ˜‡ç‡
jump_days = st.sidebar.selectbox("1. ç¬¬ä¸€æ³¢ã®ç´¯ç©æ—¥æ•°", [2, 3, 4, 5], index=1)
min_jump = st.sidebar.slider(f"2. éå»40æ—¥ã®æœ€å¤§{jump_days}æ—¥ä¸Šæ˜‡ç‡(%)", 10, 80, 20, 1)

# â‘¡ æ¯æ¸‡ï¼šä¸­å¤®å€¤ãƒ™ãƒ¼ã‚¹RVOL
vol_dry_limit = st.sidebar.slider("3. å‡ºæ¥é«˜æ¯æ¸‡åº¦ï¼ˆå½“æ—¥/20æ—¥ä¸­å¤®å€¤ï¼‰ä¸Šé™", 0.05, 1.5, 0.55, 0.05)

# â‘¢ 25MA ä¹–é›¢
ma_near_pct = st.sidebar.slider("4. 25æ—¥ç·šã¨ã®ä¹–é›¢(Â±%)", 0.5, 10.0, 2.0, 0.1)

# â‘£ æºœã‚ï¼šATRåç¸®
atr_contract_limit = st.sidebar.slider("5. ATRåç¸®ï¼ˆATR5/ATR20ï¼‰ä¸Šé™", 0.3, 1.2, 0.75, 0.05)

# â‘¤ ä»•æ›ã‘ãŒè¿‘ã„ï¼š20æ—¥é«˜å€¤ã¾ã§ã®è·é›¢
dist_to_high_limit = st.sidebar.slider("6. 20æ—¥é«˜å€¤ã¾ã§ã®è·é›¢(%) ä¸Šé™", 0.5, 10.0, 3.0, 0.1)

# â‘¥ MAã®å‘ã
require_ma_up = st.sidebar.checkbox("7. 25MAãŒä¸Šå‘ãï¼ˆ5æ—¥å‰æ¯”+ï¼‰ã‚’å¿…é ˆ", value=True)

st.sidebar.subheader("ğŸ§ª å®Ÿè¡Œè¨­å®š")
batch_size = st.sidebar.slider("ãƒãƒƒãƒã‚µã‚¤ã‚ºï¼ˆyfinanceä¸€æ‹¬å–å¾—ï¼‰", 10, 100, 50, 5)
use_auto_adjust = st.sidebar.checkbox("ä¾¡æ ¼ã‚’èª¿æ•´ï¼ˆauto_adjust=Trueï¼‰", value=True)
scan_period = st.sidebar.selectbox("å–å¾—æœŸé–“", ["3mo", "6mo", "1y"], index=1)

# ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ï¼ˆStreamlitå´ã®cache_dataï¼‰
if st.sidebar.button("ğŸ”„ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢"):
    st.cache_data.clear()
    st.rerun()

# =========================
# 3. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
# =========================
@st.cache_data(ttl=3600)
def load_master_data(market_name: str) -> Tuple[List[str], Dict[str, str]]:
    """å¸‚å ´ã”ã¨ã«éŠ˜æŸ„ãƒªã‚¹ãƒˆã‚’èª­ã¿è¾¼ã‚€ï¼ˆTSE CSVï¼‰"""
    with urllib.request.urlopen(GITHUB_CSV_URL) as resp:
        df = pd.read_csv(BytesIO(resp.read()))

    m_key = f"{market_name}ï¼ˆå†…å›½æ ªå¼ï¼‰"
    df_filtered = df[(df["å¸‚å ´ãƒ»å•†å“åŒºåˆ†"] == m_key) & (df["33æ¥­ç¨®åŒºåˆ†"] != "ï¼")].copy()

    tickers = [f"{str(code).split('.')[0]}.T" for code in df_filtered["ã‚³ãƒ¼ãƒ‰"]]
    info = {f"{str(row['ã‚³ãƒ¼ãƒ‰']).split('.')[0]}.T": row["éŠ˜æŸ„å"] for _, row in df_filtered.iterrows()}
    return tickers, info


def compute_atr(df: pd.DataFrame, period: int) -> pd.Series:
    """ATRï¼ˆå˜ç´”ç§»å‹•å¹³å‡ï¼‰"""
    high = df["High"]
    low = df["Low"]
    close = df["Close"]
    prev_close = close.shift(1)

    tr = pd.concat(
        [(high - low).abs(), (high - prev_close).abs(), (low - prev_close).abs()],
        axis=1,
    ).max(axis=1)

    return tr.rolling(period).mean()


def check_strategy(
    data: pd.DataFrame,
    *,
    min_avg_value_: float,
    jump_days_: int,
    min_jump_: float,
    vol_dry_limit_: float,
    ma_near_pct_: float,
    atr_contract_limit_: float,
    dist_to_high_limit_: float,
    require_ma_up_: bool,
) -> Tuple[bool, str, Dict[str, float]]:
    """
    ç²¾åº¦UPç‰ˆã€ŒäºŒæ®µä¸Šã’ã€åˆ¤å®š + ã‚¹ã‚³ã‚¢ç”¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¿”å´
    """
    need_len = max(60, 25 + 5, 20 + jump_days_)
    if len(data) < need_len:
        return False, "ãƒ‡ãƒ¼ã‚¿ä¸è¶³", {}

    c = data["Close"].astype(float)
    v = data["Volume"].astype(float)

    # 0) å£²è²·ä»£é‡‘ï¼ˆç›´è¿‘5æ—¥å¹³å‡/å„„å††ï¼‰
    avg_val = (c * v).tail(5).mean() / 1e8
    if avg_val < min_avg_value_:
        return False, "å£²è²·ä»£é‡‘ä¸è¶³", {"avg_val": float(avg_val)}

    # 1) ç¬¬ä¸€æ³¢ï¼šéå»40æ—¥ã§æœ€å¤§ã€Œjump_daysæ—¥ã€ä¸Šæ˜‡ç‡
    #    ä¾‹ï¼‰3æ—¥ä¸Šæ˜‡ç‡ = Close / Close.shift(3) - 1
    jump_series = (c / c.shift(jump_days_) - 1.0) * 100.0
    max_jump = jump_series.tail(40).max()
    if pd.isna(max_jump) or max_jump < min_jump_:
        return False, "ç¬¬ä¸€æ³¢å¼±ã„", {"max_jump": float(max_jump) if pd.notna(max_jump) else 0.0}

    # 2) å‡ºæ¥é«˜æ¯æ¸‡ï¼šå½“æ—¥ / 20æ—¥ä¸­å¤®å€¤ï¼ˆç•°å¸¸æ—¥è€æ€§ï¼‰
    v_med20 = v.tail(20).median()
    rvol_med = (v.iloc[-1] / v_med20) if v_med20 > 0 else 9.9
    if rvol_med > vol_dry_limit_:
        return False, "æ¯æ¸‡ã—ã¦ãªã„", {"rvol": float(rvol_med)}

    # 3) 25MA ä¹–é›¢
    ma25 = c.rolling(25).mean().iloc[-1]
    curr_p = c.iloc[-1]
    diff_ma25 = abs(curr_p - ma25) / ma25 * 100.0
    if diff_ma25 > ma_near_pct_:
        return False, "25MAä¹–é›¢å¤§", {"diff_ma25": float(diff_ma25)}

    # 4) æºœã‚ï¼šATRåç¸®ï¼ˆATR5/ATR20ï¼‰
    atr5 = compute_atr(data, 5).iloc[-1]
    atr20 = compute_atr(data, 20).iloc[-1]
    atr_ratio = (atr5 / atr20) if atr20 and atr20 > 0 else 9.9
    if atr_ratio > atr_contract_limit_:
        return False, "ãƒœãƒ©åç¸®å¼±ã„", {"atr_ratio": float(atr_ratio)}

    # 5) ä»•æ›ã‘ãŒè¿‘ã„ï¼š20æ—¥é«˜å€¤ã¾ã§ã®è·é›¢
    high20 = c.tail(20).max()
    dist_to_high = (high20 - curr_p) / curr_p * 100.0
    if dist_to_high > dist_to_high_limit_:
        return False, "é«˜å€¤ã¾ã§é ã„", {"dist_to_high": float(dist_to_high)}

    # 6) 25MAã®å‘ã
    ma25_slope = (c.rolling(25).mean().iloc[-1]) - (c.rolling(25).mean().shift(5).iloc[-1])
    if require_ma_up_ and not (ma25_slope > 0):
        return False, "MAä¸‹å‘ã", {"ma25_slope": float(ma25_slope)}

    metrics = {
        "avg_val": float(avg_val),
        "max_jump": float(max_jump),
        "rvol": float(rvol_med),
        "diff_ma25": float(diff_ma25),
        "atr_ratio": float(atr_ratio),
        "dist_to_high": float(dist_to_high),
        "ma25_slope": float(ma25_slope),
        "price": float(curr_p),
    }
    return True, "OK", metrics


def score_metrics(m: Dict[str, float]) -> float:
    """
    ã‚¹ã‚³ã‚¢ï¼ˆä¸Šä½å€™è£œã‚’ä¸¦ã¹ã‚‹ãŸã‚ï¼‰
    - ç¬¬ä¸€æ³¢å¼·ã„ã»ã© +ï¼ˆmax_jumpï¼‰
    - æ¯æ¸‡ã—ã¦ã‚‹ã»ã© +ï¼ˆrvolãŒä½ã„ï¼‰
    - ãƒœãƒ©åç¸®ã»ã© +ï¼ˆatr_ratioãŒä½ã„ï¼‰
    - é«˜å€¤ãŒè¿‘ã„ã»ã© +ï¼ˆdist_to_highãŒä½ã„ï¼‰
    - 25MAä¹–é›¢ã¯å°ã•ã„ã»ã© +
    - MAä¸Šå‘ãã¯å°‘ã—åŠ ç‚¹
    """
    # ä¹±æš´ã«ã‚¯ãƒªãƒƒãƒ—ã—ã¦å®‰å®šåŒ–ï¼ˆæ¥µç«¯å€¤ã®å½±éŸ¿ã‚’æŠ‘ãˆã‚‹ï¼‰
    max_jump = max(0.0, min(m.get("max_jump", 0.0), 200.0))
    rvol = max(0.01, min(m.get("rvol", 9.9), 9.9))
    atr_ratio = max(0.01, min(m.get("atr_ratio", 9.9), 9.9))
    dist = max(0.0, min(m.get("dist_to_high", 99.0), 99.0))
    diff = max(0.0, min(m.get("diff_ma25", 99.0), 99.0))
    slope = m.get("ma25_slope", 0.0)

    # 0ã€œ1ã£ã½ã„æŒ‡æ¨™ã«å¯„ã›ã‚‹ï¼ˆç°¡æ˜“ï¼‰
    s_jump = max_jump / 80.0  # 80%ã§1ä»˜è¿‘
    s_rvol = 1.0 / rvol       # å°ã•ã„ã»ã©é«˜å¾—ç‚¹
    s_atr = 1.0 / atr_ratio
    s_dist = 1.0 / (1.0 + dist)
    s_diff = 1.0 / (1.0 + diff)
    s_slope = 0.15 if slope > 0 else 0.0

    # ã‚¦ã‚§ã‚¤ãƒˆï¼ˆå¥½ã¿ã«åˆã‚ã›ã¦èª¿æ•´ã—ã¦OKï¼‰
    return (
        1.30 * s_jump +
        1.10 * s_rvol +
        1.10 * s_atr +
        0.90 * s_dist +
        0.70 * s_diff +
        s_slope
    )


# =========================
# 4. ãƒ¡ã‚¤ãƒ³ç”»é¢
# =========================
st.title(f"ğŸš€ {target_market}ãƒ»äºŒæ®µä¸Šã’ç‹™ã„ï¼ˆç²¾åº¦UPç‰ˆï¼‰")
st.caption("ç¬¬ä¸€æ³¢ï¼ˆè¤‡æ•°æ—¥ä¸Šæ˜‡ï¼‰â†’æ¯æ¸‡ï¼ˆä¸­å¤®å€¤RVOLï¼‰â†’25MAä»˜è¿‘â†’ATRåç¸®â†’é«˜å€¤ãŒè¿‘ã„ã€ã§â€œæ˜æ—¥ã€œæ•°æ—¥â€å¯„ã›ã€‚")

colA, colB, colC = st.columns([1.1, 1.1, 1.6])
with colA:
    st.write("**ã‚¹ã‚­ãƒ£ãƒ³å¯¾è±¡**")
    st.write(f"- å¸‚å ´: {target_market}")
    st.write(f"- æœŸé–“: {scan_period} / 1d")

with colB:
    st.write("**ä¸»è¦æ¡ä»¶**")
    st.write(f"- å£²è²·ä»£é‡‘: {min_avg_value:.2f}å„„/æ—¥ä»¥ä¸Š")
    st.write(f"- ç¬¬ä¸€æ³¢: {jump_days}æ—¥ã§{min_jump:.0f}%ä»¥ä¸Š")
    st.write(f"- æ¯æ¸‡: RVOLâ‰¤{vol_dry_limit:.2f}")

with colC:
    st.write("**ãƒˆãƒªã‚¬ãƒ¼å¯„ã›**")
    st.write(f"- 25MAä¹–é›¢â‰¤{ma_near_pct:.1f}% / ATR5/20â‰¤{atr_contract_limit:.2f} / é«˜å€¤è·é›¢â‰¤{dist_to_high_limit:.1f}%")
    st.write(f"- 25MAä¸Šå‘ãå¿…é ˆ: {'ON' if require_ma_up else 'OFF'}")

# å®Ÿè¡Œ
if st.button("ğŸ“¡ ã‚¹ã‚­ãƒ£ãƒ³é–‹å§‹", type="primary"):
    try:
        tickers, info_db = load_master_data(target_market)
    except Exception as e:
        st.error(f"ãƒã‚¹ã‚¿ãƒ¼èª­ã¿è¾¼ã¿å¤±æ•—: {e}")
        st.stop()

    if not tickers:
        st.warning("å¯¾è±¡éŠ˜æŸ„ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        st.stop()

    results: List[Dict[str, object]] = []
    fail_reasons: Dict[str, int] = {}
    fetch_fail: List[str] = []

    progress_bar = st.progress(0)
    status_text = st.empty()

    # yfinanceã§ä¸€æ‹¬å–å¾—
    total = len(tickers)
    t0 = time.time()

    for i in range(0, total, batch_size):
        batch = tickers[i : i + batch_size]
        status_text.text(f"ã‚¹ã‚­ãƒ£ãƒ³ä¸­... {i}/{total}")
        progress_bar.progress(min(1.0, i / total))

        try:
            df_batch = yf.download(
                batch,
                period=scan_period,
                interval="1d",
                progress=False,
                group_by="ticker",
                threads=True,
                auto_adjust=use_auto_adjust,
            )

            # 1éŠ˜æŸ„ã®ã¿ã®æ§‹é€ è£œæ­£
            if not isinstance(df_batch.columns, pd.MultiIndex):
                df_batch = pd.concat({batch[0]: df_batch}, axis=1)

            for t in batch:
                # å–å¾—æ¼ã‚Œ
                if t not in df_batch.columns.levels[0]:
                    fetch_fail.append(t)
                    continue

                stock_data = df_batch[t].dropna()
                ok, reason, m = check_strategy(
                    stock_data,
                    min_avg_value_=min_avg_value,
                    jump_days_=jump_days,
                    min_jump_=min_jump,
                    vol_dry_limit_=vol_dry_limit,
                    ma_near_pct_=ma_near_pct,
                    atr_contract_limit_=atr_contract_limit,
                    dist_to_high_limit_=dist_to_high_limit,
                    require_ma_up_=require_ma_up,
                )

                if not ok:
                    fail_reasons[reason] = fail_reasons.get(reason, 0) + 1
                    continue

                sc = score_metrics(m)
                results.append(
                    {
                        "ã‚³ãƒ¼ãƒ‰": t.replace(".T", ""),
                        "éŠ˜æŸ„å": info_db.get(t, "ä¸æ˜"),
                        "ã‚¹ã‚³ã‚¢": float(sc),
                        "ç¾åœ¨å€¤": float(m["price"]),
                        f"ç¬¬ä¸€æ³¢({jump_days}æ—¥)%": float(m["max_jump"]),
                        "æ¯æ¸‡RVOL(ä¸­å¤®å€¤)": float(m["rvol"]),
                        "25MAä¹–é›¢%": float(m["diff_ma25"]),
                        "ATR5/20": float(m["atr_ratio"]),
                        "é«˜å€¤è·é›¢%": float(m["dist_to_high"]),
                        "ä»£é‡‘(å„„å††)": float(m["avg_val"]),
                    }
                )

        except Exception:
            # ãƒãƒƒãƒå˜ä½ã§è½ã¡ãŸå ´åˆã¯å…¨éƒ¨å–å¾—å¤±æ•—æ‰±ã„
            fetch_fail.extend(batch)
            continue

    progress_bar.progress(1.0)
    status_text.empty()

    elapsed = time.time() - t0

    # ã‚µãƒãƒªãƒ¼
    st.subheader("çµæœã‚µãƒãƒªãƒ¼")
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("ãƒ’ãƒƒãƒˆéŠ˜æŸ„æ•°", f"{len(results)}")
    c2.metric("å¯¾è±¡éŠ˜æŸ„æ•°", f"{total}")
    c3.metric("å–å¾—å¤±æ•—æ•°", f"{len(fetch_fail)}")
    c4.metric("å‡¦ç†æ™‚é–“(ç§’)", f"{elapsed:.1f}")

    if fail_reasons:
        with st.expander("è½é¸ç†ç”±ã®å†…è¨³ï¼ˆãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ï¼‰", expanded=False):
            reason_df = pd.DataFrame(
                [{"ç†ç”±": k, "ä»¶æ•°": v} for k, v in sorted(fail_reasons.items(), key=lambda x: -x[1])]
            )
            st.dataframe(reason_df, use_container_width=True, hide_index=True)

    if fetch_fail:
        with st.expander("å–å¾—å¤±æ•—ãƒ†ã‚£ãƒƒã‚«ãƒ¼ï¼ˆyfinanceæ¬ æãªã©ï¼‰", expanded=False):
            st.write(", ".join(fetch_fail[:300]) + (" ..." if len(fetch_fail) > 300 else ""))

    # ãƒ¡ã‚¤ãƒ³çµæœ
    if not results:
        st.warning("è©²å½“éŠ˜æŸ„ãªã—ã€‚ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç·©ã‚ã¦ã¿ã¦ãã ã•ã„ã€‚")
        st.stop()

    st.success(f"ğŸ¯ {len(results)} éŠ˜æŸ„ãŒæ¡ä»¶ã«åˆè‡´ã—ã¾ã—ãŸï¼ˆã‚¹ã‚³ã‚¢é †ï¼‰")

    res_df = pd.DataFrame(results).sort_values("ã‚¹ã‚³ã‚¢", ascending=False).reset_index(drop=True)

    # è¡¨ç¤ºç”¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆè¡¨ç¤ºã¯ç¶ºéº—ã«ã€ã‚½ãƒ¼ãƒˆã¯æ•°å€¤ã®ã¾ã¾ï¼‰
    show_df = res_df.copy()
    show_df["ã‚¹ã‚³ã‚¢"] = show_df["ã‚¹ã‚³ã‚¢"].map(lambda x: f"{x:.3f}")
    show_df["ç¾åœ¨å€¤"] = show_df["ç¾åœ¨å€¤"].map(lambda x: f"{x:,.1f}")
    show_df[f"ç¬¬ä¸€æ³¢({jump_days}æ—¥)%"] = show_df[f"ç¬¬ä¸€æ³¢({jump_days}æ—¥)%"].map(lambda x: f"{x:.1f}%")
    show_df["æ¯æ¸‡RVOL(ä¸­å¤®å€¤)"] = show_df["æ¯æ¸‡RVOL(ä¸­å¤®å€¤)"].map(lambda x: f"{x:.2f}å€")
    show_df["25MAä¹–é›¢%"] = show_df["25MAä¹–é›¢%"].map(lambda x: f"{x:.1f}%")
    show_df["ATR5/20"] = show_df["ATR5/20"].map(lambda x: f"{x:.2f}")
    show_df["é«˜å€¤è·é›¢%"] = show_df["é«˜å€¤è·é›¢%"].map(lambda x: f"{x:.1f}%")
    show_df["ä»£é‡‘(å„„å††)"] = show_df["ä»£é‡‘(å„„å††)"].map(lambda x: f"{x:.2f}å„„å††")

    st.dataframe(show_df, use_container_width=True, hide_index=True)

    # ãƒãƒ£ãƒ¼ãƒˆç¢ºèªå°ç·š
    st.subheader("å€™è£œãƒãƒ£ãƒ¼ãƒˆï¼ˆãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯ç¢ºèªï¼‰")
    pick_code = st.selectbox(
        "éŠ˜æŸ„ã‚’é¸æŠ",
        options=res_df["ã‚³ãƒ¼ãƒ‰"].tolist(),
        index=0,
    )
    pick_ticker = f"{pick_code}.T"

    # é¸æŠéŠ˜æŸ„ã‚’å–å¾—ã—ã¦è¡¨ç¤ºï¼ˆè»½é‡ã«ç›´è¿‘6moå›ºå®šã§ã‚‚OKã ãŒã€ã“ã“ã¯scan_periodã«åˆã‚ã›ã‚‹ï¼‰
    try:
        df_one = yf.download(
            pick_ticker,
            period=scan_period,
            interval="1d",
            progress=False,
            auto_adjust=use_auto_adjust,
        ).dropna()

        if len(df_one) >= 10:
            st.write(f"**{pick_code}ï¼š{info_db.get(pick_ticker, 'ä¸æ˜')}**")
            st.line_chart(df_one["Close"], height=260)
            st.bar_chart(df_one["Volume"], height=180)
        else:
            st.info("ãƒãƒ£ãƒ¼ãƒˆè¡¨ç¤ºã«ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    except Exception as e:
        st.warning(f"ãƒãƒ£ãƒ¼ãƒˆå–å¾—ã«å¤±æ•—: {e}")

    # å‚è€ƒãƒªãƒ³ã‚¯ï¼ˆTradingView / Kabutanç­‰ã¯å¿…è¦ã«å¿œã˜ã¦å¥½ã¿ã§ï¼‰
    with st.expander("å¤–éƒ¨ãƒªãƒ³ã‚¯ï¼ˆç¢ºèªç”¨ï¼‰", expanded=False):
        st.write(f"- TradingView: https://www.tradingview.com/symbols/TSE-{pick_code}/")
        st.write(f"- æ ªæ¢: https://kabutan.jp/stock/?code={pick_code}")

else:
    st.info("å·¦ã®æ¡ä»¶ã‚’èª¿æ•´ã—ã¦ã€ŒğŸ“¡ ã‚¹ã‚­ãƒ£ãƒ³é–‹å§‹ã€ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
