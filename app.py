# app.py
from __future__ import annotations

import time
import urllib.request
from io import BytesIO
from typing import Dict, List, Tuple

import numpy as np
import pandas as pd
import streamlit as st
import yfinance as yf

# =========================
# 1. ã‚¢ãƒ—ãƒªè¨­å®š & èªè¨¼
# =========================
st.set_page_config(page_title="äºŒæ®µä¸Šã’ã‚¹ã‚­ãƒ£ãƒŠãƒ¼", layout="wide")
MY_PASSWORD = "stock testa"  # â€»è¦æœ›ã«ã‚ˆã‚Šç›´æ›¸ãã®ã¾ã¾

if "auth" not in st.session_state:
    st.session_state.auth = False

if not st.session_state.auth:
    st.title("ðŸ”’ èªè¨¼")
    pwd = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password")
    if pwd == MY_PASSWORD:
        st.session_state.auth = True
        st.rerun()
    st.stop()

# =========================
# 2. ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®šï¼ˆæ¡ä»¶æŒ‡å®šï¼‰
# =========================
st.sidebar.title("âš™ï¸ ã‚¹ã‚­ãƒ£ãƒ³æ¡ä»¶")

GITHUB_CSV_URL = "https://raw.githubusercontent.com/watarai0202-netizen/stocktest-app-1/main/data_j.csv"

target_market = st.sidebar.radio("ðŸ“Š å¸‚å ´é¸æŠž", ("ã‚°ãƒ­ãƒ¼ã‚¹", "ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰", "ãƒ—ãƒ©ã‚¤ãƒ "), index=0)

st.sidebar.subheader("ðŸš« ä¸äººæ°—ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼")
min_avg_value = st.sidebar.slider("æœ€ä½Žå£²è²·ä»£é‡‘(5æ—¥å¹³å‡/å„„å††)", 0.1, 10.0, 0.5, 0.1)

st.sidebar.subheader("ðŸ“ˆ äºŒæ®µä¸Šã’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆç²¾åº¦UPç‰ˆï¼‰")
jump_days = st.sidebar.selectbox("1. ç¬¬ä¸€æ³¢ã®ç´¯ç©æ—¥æ•°", [2, 3, 4, 5], index=1)
min_jump = st.sidebar.slider(f"2. éŽåŽ»40æ—¥ã®æœ€å¤§{jump_days}æ—¥ä¸Šæ˜‡çŽ‡(%)", 10, 80, 20, 1)
vol_dry_limit = st.sidebar.slider("3. å‡ºæ¥é«˜æž¯æ¸‡åº¦ï¼ˆå½“æ—¥/20æ—¥ä¸­å¤®å€¤ï¼‰ä¸Šé™", 0.05, 1.5, 0.55, 0.05)
ma_near_pct = st.sidebar.slider("4. 25æ—¥ç·šã¨ã®ä¹–é›¢(Â±%)", 0.5, 10.0, 2.0, 0.1)
atr_contract_limit = st.sidebar.slider("5. ATRåŽç¸®ï¼ˆATR5/ATR20ï¼‰ä¸Šé™", 0.3, 1.2, 0.75, 0.05)
dist_to_high_limit = st.sidebar.slider("6. 20æ—¥é«˜å€¤ã¾ã§ã®è·é›¢(%) ä¸Šé™", 0.5, 10.0, 3.0, 0.1)
require_ma_up = st.sidebar.checkbox("7. 25MAãŒä¸Šå‘ãï¼ˆ5æ—¥å‰æ¯”+ï¼‰ã‚’å¿…é ˆ", value=True)

st.sidebar.subheader("ðŸ§ª å®Ÿè¡Œè¨­å®š")
batch_size = st.sidebar.slider("ãƒãƒƒãƒã‚µã‚¤ã‚ºï¼ˆyfinanceä¸€æ‹¬å–å¾—ï¼‰", 10, 100, 50, 5)
use_auto_adjust = st.sidebar.checkbox("ä¾¡æ ¼ã‚’èª¿æ•´ï¼ˆauto_adjust=Trueï¼‰", value=True)
scan_period = st.sidebar.selectbox("ã‚¹ã‚­ãƒ£ãƒ³ç”¨ å–å¾—æœŸé–“", ["3mo", "6mo", "1y"], index=1)

st.sidebar.subheader("ðŸ§ª ä¸Šä½ã ã‘ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ")
enable_backtest = st.sidebar.checkbox("ä¸Šä½å€™è£œã®ã¿ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã™ã‚‹", value=True)
top_n_bt = st.sidebar.slider("ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå¯¾è±¡ï¼ˆã‚¹ã‚³ã‚¢ä¸Šä½Nï¼‰", 1, 80, 20, 1)
bt_period = st.sidebar.selectbox("ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆæœŸé–“", ["6mo", "1y", "2y", "5y"], index=2)
bt_horizon = st.sidebar.selectbox("å°†æ¥ã®è©•ä¾¡æœŸé–“ï¼ˆkå–¶æ¥­æ—¥ï¼‰", [3, 5, 10, 15, 20], index=1)
bt_hit_threshold = st.sidebar.slider("å‘½ä¸­åˆ¤å®šï¼ˆkæ—¥å†… æœ€å¤§ä¸Šæ˜‡ãŒ +ä½•% ä»¥ä¸Šï¼‰", 3, 40, 10, 1)

# ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢
if st.sidebar.button("ðŸ”„ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢"):
    st.cache_data.clear()
    st.rerun()

# =========================
# 3. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
# =========================
@st.cache_data(ttl=3600)
def load_master_data(market_name: str) -> Tuple[List[str], Dict[str, str]]:
    with urllib.request.urlopen(GITHUB_CSV_URL) as resp:
        df = pd.read_csv(BytesIO(resp.read()))

    m_key = f"{market_name}ï¼ˆå†…å›½æ ªå¼ï¼‰"
    df_filtered = df[(df["å¸‚å ´ãƒ»å•†å“åŒºåˆ†"] == m_key) & (df["33æ¥­ç¨®åŒºåˆ†"] != "ï¼")].copy()

    tickers = [f"{str(code).split('.')[0]}.T" for code in df_filtered["ã‚³ãƒ¼ãƒ‰"]]
    info = {f"{str(row['ã‚³ãƒ¼ãƒ‰']).split('.')[0]}.T": row["éŠ˜æŸ„å"] for _, row in df_filtered.iterrows()}
    return tickers, info


def fetch_ohlcv(ticker: str, period: str, auto_adjust: bool) -> pd.DataFrame:
    """
    yfinanceãŒHigh/Lowã‚’è¿”ã•ãªã„ãƒ»NaNãŒæ··ã–ã‚‹ã‚±ãƒ¼ã‚¹ã§ã‚‚
    å¯èƒ½ãªé™ã‚Šãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå¯èƒ½ãªOHLCVã«æ•´å½¢ã™ã‚‹ã€‚
    """
    df = yf.download(
        ticker,
        period=period,
        interval="1d",
        progress=False,
        auto_adjust=auto_adjust,
    )

    if df is None or df.empty:
        return pd.DataFrame()

    # CloseãŒç„¡ã„ã¨ä½•ã‚‚ã§ããªã„
    if "Close" not in df.columns:
        return pd.DataFrame()

    # dropna() ã‚’å…¨åˆ—å¯¾è±¡ã«ã™ã‚‹ã¨å…¨æ¶ˆã—ã«ãªã‚Šã‚„ã™ã„ã®ã§ Close ã ã‘ã«é™å®š
    df = df.dropna(subset=["Close"]).copy()
    if df.empty:
        return pd.DataFrame()

    # æ¬ ã‘ãŒã¡ãªåˆ—ã¯ Close ã§è£œå®Œï¼ˆæ¤œè¨¼ä¸èƒ½ã‚’é¿ã‘ã‚‹ï¼‰
    for col in ["Open", "High", "Low"]:
        if col not in df.columns:
            df[col] = df["Close"]
        else:
            df[col] = df[col].fillna(df["Close"])

    if "Volume" not in df.columns:
        df["Volume"] = 0
    else:
        df["Volume"] = df["Volume"].fillna(0)

    # åž‹ã®å®‰å®šåŒ–
    for col in ["Open", "High", "Low", "Close", "Volume"]:
        df[col] = pd.to_numeric(df[col], errors="coerce")
    df = df.dropna(subset=["Close"]).copy()

    df = df.sort_index()
    return df


def compute_atr(df: pd.DataFrame, period: int) -> pd.Series:
    high = df["High"].astype(float)
    low = df["Low"].astype(float)
    close = df["Close"].astype(float)
    prev_close = close.shift(1)

    tr = pd.concat(
        [(high - low).abs(), (high - prev_close).abs(), (low - prev_close).abs()],
        axis=1,
    ).max(axis=1)

    return tr.rolling(period).mean()


def check_strategy(
    data: pd.DataFrame,
    *,
    min_avg_value_: float,
    jump_days_: int,
    min_jump_: float,
    vol_dry_limit_: float,
    ma_near_pct_: float,
    atr_contract_limit_: float,
    dist_to_high_limit_: float,
    require_ma_up_: bool,
) -> Tuple[bool, str, Dict[str, float]]:
    need_len = max(60, 25 + 5, 20 + jump_days_)
    if len(data) < need_len:
        return False, "ãƒ‡ãƒ¼ã‚¿ä¸è¶³", {}

    c = data["Close"].astype(float)
    v = data["Volume"].astype(float)

    # å£²è²·ä»£é‡‘ï¼ˆç›´è¿‘5æ—¥å¹³å‡/å„„å††ï¼‰
    avg_val = (c * v).tail(5).mean() / 1e8
    if avg_val < min_avg_value_:
        return False, "å£²è²·ä»£é‡‘ä¸è¶³", {"avg_val": float(avg_val)}

    # ç¬¬ä¸€æ³¢ï¼šéŽåŽ»40æ—¥ã§æœ€å¤§Næ—¥ä¸Šæ˜‡çŽ‡
    jump_series = (c / c.shift(jump_days_) - 1.0) * 100.0
    max_jump = jump_series.tail(40).max()
    if pd.isna(max_jump) or max_jump < min_jump_:
        return False, "ç¬¬ä¸€æ³¢å¼±ã„", {"max_jump": float(max_jump) if pd.notna(max_jump) else 0.0}

    # æž¯æ¸‡ï¼šä¸­å¤®å€¤RVOL
    v_med20 = v.tail(20).median()
    rvol_med = (v.iloc[-1] / v_med20) if v_med20 > 0 else 9.9
    if rvol_med > vol_dry_limit_:
        return False, "æž¯æ¸‡ã—ã¦ãªã„", {"rvol": float(rvol_med)}

    # 25MAä¹–é›¢
    ma25 = c.rolling(25).mean().iloc[-1]
    curr_p = c.iloc[-1]
    diff_ma25 = abs(curr_p - ma25) / ma25 * 100.0
    if diff_ma25 > ma_near_pct_:
        return False, "25MAä¹–é›¢å¤§", {"diff_ma25": float(diff_ma25)}

    # ATRåŽç¸®
    atr5 = compute_atr(data, 5).iloc[-1]
    atr20 = compute_atr(data, 20).iloc[-1]
    atr_ratio = (atr5 / atr20) if atr20 and atr20 > 0 else 9.9
    if atr_ratio > atr_contract_limit_:
        return False, "ãƒœãƒ©åŽç¸®å¼±ã„", {"atr_ratio": float(atr_ratio)}

    # é«˜å€¤è·é›¢ï¼ˆ20æ—¥ï¼‰
    high20 = c.tail(20).max()
    dist_to_high = (high20 - curr_p) / curr_p * 100.0
    if dist_to_high > dist_to_high_limit_:
        return False, "é«˜å€¤ã¾ã§é ã„", {"dist_to_high": float(dist_to_high)}

    # MAã®å‘ã
    ma25_now = c.rolling(25).mean().iloc[-1]
    ma25_prev = c.rolling(25).mean().shift(5).iloc[-1]
    ma25_slope = ma25_now - ma25_prev
    if require_ma_up_ and not (ma25_slope > 0):
        return False, "MAä¸‹å‘ã", {"ma25_slope": float(ma25_slope)}

    metrics = {
        "avg_val": float(avg_val),
        "max_jump": float(max_jump),
        "rvol": float(rvol_med),
        "diff_ma25": float(diff_ma25),
        "atr_ratio": float(atr_ratio),
        "dist_to_high": float(dist_to_high),
        "ma25_slope": float(ma25_slope),
        "price": float(curr_p),
    }
    return True, "OK", metrics


def score_metrics(m: Dict[str, float]) -> float:
    max_jump = max(0.0, min(m.get("max_jump", 0.0), 200.0))
    rvol = max(0.01, min(m.get("rvol", 9.9), 9.9))
    atr_ratio = max(0.01, min(m.get("atr_ratio", 9.9), 9.9))
    dist = max(0.0, min(m.get("dist_to_high", 99.0), 99.0))
    diff = max(0.0, min(m.get("diff_ma25", 99.0), 99.0))
    slope = m.get("ma25_slope", 0.0)

    s_jump = max_jump / 80.0
    s_rvol = 1.0 / rvol
    s_atr = 1.0 / atr_ratio
    s_dist = 1.0 / (1.0 + dist)
    s_diff = 1.0 / (1.0 + diff)
    s_slope = 0.15 if slope > 0 else 0.0

    return (
        1.30 * s_jump +
        1.10 * s_rvol +
        1.10 * s_atr +
        0.90 * s_dist +
        0.70 * s_diff +
        s_slope
    )


# =========================
# 4. ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆï¼ˆä¸Šä½ã ã‘ï¼‰
# =========================
def compute_signal_series(
    df: pd.DataFrame,
    *,
    min_avg_value_: float,
    jump_days_: int,
    min_jump_: float,
    vol_dry_limit_: float,
    ma_near_pct_: float,
    atr_contract_limit_: float,
    dist_to_high_limit_: float,
    require_ma_up_: bool,
) -> pd.Series:
    df = df.copy()
    c = df["Close"].astype(float)
    v = df["Volume"].astype(float)

    avg_val = (c * v).rolling(5).mean() / 1e8

    jump = (c / c.shift(jump_days_) - 1.0) * 100.0
    max_jump_40 = jump.rolling(40).max()

    v_med20 = v.rolling(20).median()
    rvol_med = v / v_med20

    ma25 = c.rolling(25).mean()
    diff_ma25 = (c - ma25).abs() / ma25 * 100.0

    atr5 = compute_atr(df, 5)
    atr20 = compute_atr(df, 20)
    atr_ratio = atr5 / atr20

    high20 = c.rolling(20).max()
    dist_to_high = (high20 - c) / c * 100.0

    ma25_slope = ma25 - ma25.shift(5)

    cond = (
        (avg_val >= min_avg_value_) &
        (max_jump_40 >= min_jump_) &
        (rvol_med <= vol_dry_limit_) &
        (diff_ma25 <= ma_near_pct_) &
        (atr_ratio <= atr_contract_limit_) &
        (dist_to_high <= dist_to_high_limit_)
    )
    if require_ma_up_:
        cond = cond & (ma25_slope > 0)

    return cond.fillna(False)


def backtest_one(df: pd.DataFrame, signal: pd.Series, horizon: int) -> pd.DataFrame:
    df = df.copy()
    df = df.loc[signal.index]

    c = df["Close"].astype(float).to_numpy()
    h = df["High"].astype(float).to_numpy()
    l = df["Low"].astype(float).to_numpy()
    sig = signal.to_numpy()

    idxs = np.where(sig)[0]
    rows = []
    n = len(df)

    for i in idxs:
        if i + 1 >= n:
            continue
        end = min(n, i + 1 + horizon)

        base = c[i]
        if not np.isfinite(base) or base <= 0:
            continue

        max_high = np.nanmax(h[i + 1:end])
        min_low = np.nanmin(l[i + 1:end])

        max_up = (max_high / base - 1.0) * 100.0 if np.isfinite(max_high) else np.nan
        max_dd = (min_low / base - 1.0) * 100.0 if np.isfinite(min_low) else np.nan

        rows.append(
            {
                "date": df.index[i],
                "base_close": base,
                "max_up_%": max_up,
                "max_dd_%": max_dd,
            }
        )
    return pd.DataFrame(rows)


@st.cache_data(ttl=3600)
def run_backtest_top(
    tickers: List[str],
    *,
    period: str,
    auto_adjust: bool,
    min_avg_value_: float,
    jump_days_: int,
    min_jump_: float,
    vol_dry_limit_: float,
    ma_near_pct_: float,
    atr_contract_limit_: float,
    dist_to_high_limit_: float,
    require_ma_up_: bool,
    horizon: int,
    hit_threshold: float,
) -> Tuple[pd.DataFrame, pd.DataFrame]:
    summaries = []
    all_trades = []

    for t in tickers:
        df = fetch_ohlcv(t, period=period, auto_adjust=auto_adjust)
        if df.empty:
            summaries.append(
                {
                    "ticker": t,
                    "signals": 0,
                    "hit_rate_%": np.nan,
                    f"avg_max_up_{horizon}d_%": np.nan,
                    f"med_max_up_{horizon}d_%": np.nan,
                    f"worst_dd_{horizon}d_%": np.nan,
                }
            )
            continue

        sig = compute_signal_series(
            df,
            min_avg_value_=min_avg_value_,
            jump_days_=jump_days_,
            min_jump_=min_jump_,
            vol_dry_limit_=vol_dry_limit_,
            ma_near_pct_=ma_near_pct_,
            atr_contract_limit_=atr_contract_limit_,
            dist_to_high_limit_=dist_to_high_limit_,
            require_ma_up_=require_ma_up_,
        )

        trades = backtest_one(df, sig, horizon=horizon)
        if trades.empty:
            summaries.append(
                {
                    "ticker": t,
                    "signals": 0,
                    "hit_rate_%": np.nan,
                    f"avg_max_up_{horizon}d_%": np.nan,
                    f"med_max_up_{horizon}d_%": np.nan,
                    f"worst_dd_{horizon}d_%": np.nan,
                }
            )
            continue

        hit = (trades["max_up_%"] >= hit_threshold).mean() * 100.0
        avg_up = float(np.nanmean(trades["max_up_%"]))
        med_up = float(np.nanmedian(trades["max_up_%"]))
        worst_dd = float(np.nanmin(trades["max_dd_%"]))

        summaries.append(
            {
                "ticker": t,
                "signals": int(len(trades)),
                "hit_rate_%": float(hit),
                f"avg_max_up_{horizon}d_%": avg_up,
                f"med_max_up_{horizon}d_%": med_up,
                f"worst_dd_{horizon}d_%": worst_dd,
            }
        )

        trades_out = trades.copy()
        trades_out["ticker"] =_
