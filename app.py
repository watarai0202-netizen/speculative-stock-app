# app.py
from __future__ import annotations

import time
import urllib.request
from io import BytesIO
from typing import Dict, List, Tuple

import numpy as np
import pandas as pd
import streamlit as st
import yfinance as yf

# =========================
# 1. ã‚¢ãƒ—ãƒªè¨­å®š & èªè¨¼
# =========================
st.set_page_config(page_title="äºŒæ®µä¸Šã’ã‚¹ã‚­ãƒ£ãƒŠãƒ¼", layout="wide")
MY_PASSWORD = "stock testa"  # â€»è¦æœ›ã«ã‚ˆã‚Šç›´æ›¸ãã®ã¾ã¾

if "auth" not in st.session_state:
    st.session_state.auth = False

if not st.session_state.auth:
    st.title("ğŸ”’ èªè¨¼")
    pwd = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password")
    if pwd == MY_PASSWORD:
        st.session_state.auth = True
        st.rerun()
    st.stop()

# =========================
# 2. ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
# =========================
st.sidebar.title("âš™ï¸ ã‚¹ã‚­ãƒ£ãƒ³æ¡ä»¶")

GITHUB_CSV_URL = "https://raw.githubusercontent.com/watarai0202-netizen/stocktest-app-1/main/data_j.csv"
target_market = st.sidebar.radio("ğŸ“Š å¸‚å ´é¸æŠ", ("ã‚°ãƒ­ãƒ¼ã‚¹", "ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰", "ãƒ—ãƒ©ã‚¤ãƒ "), index=0)

st.sidebar.subheader("ğŸš« è¶³åˆ‡ã‚Šï¼ˆã“ã“ã ã‘ã¯å®ˆã‚‹ï¼‰")
min_avg_value = st.sidebar.slider("æœ€ä½å£²è²·ä»£é‡‘(5æ—¥å¹³å‡/å„„å††)", 0.1, 10.0, 0.5, 0.1)
vol_dry_limit = st.sidebar.slider("å‡ºæ¥é«˜æ¯æ¸‡åº¦ï¼ˆå½“æ—¥/20æ—¥ä¸­å¤®å€¤ï¼‰ä¸Šé™", 0.05, 2.0, 0.70, 0.05)
ma_near_pct = st.sidebar.slider("25æ—¥ç·šã¨ã®ä¹–é›¢(Â±%) ä¸Šé™", 0.5, 15.0, 4.0, 0.1)

st.sidebar.subheader("â­ ã‚¹ã‚³ã‚¢åŠ ç‚¹ï¼ˆè½ã¨ã•ãªã„ãƒ»é †ä½ä»˜ã‘ç”¨ï¼‰")
jump_days = st.sidebar.selectbox("ç¬¬ä¸€æ³¢ã®ç´¯ç©æ—¥æ•°ï¼ˆåŠ ç‚¹ï¼‰", [2, 3, 4, 5], index=1)
min_jump = st.sidebar.slider(f"éå»40æ—¥ã®æœ€å¤§{jump_days}æ—¥ä¸Šæ˜‡ç‡(%)ï¼ˆåŠ ç‚¹ï¼‰", 5, 80, 15, 1)
atr_contract_limit = st.sidebar.slider("ATRåç¸®ï¼ˆATR5/ATR20ï¼‰ç›®å®‰ï¼ˆåŠ ç‚¹ï¼‰", 0.3, 1.5, 0.85, 0.05)
dist_to_high_limit = st.sidebar.slider("20æ—¥é«˜å€¤ã¾ã§ã®è·é›¢(%) ç›®å®‰ï¼ˆåŠ ç‚¹ï¼‰", 0.5, 20.0, 6.0, 0.1)
require_ma_up = st.sidebar.checkbox("25MAãŒä¸Šå‘ãï¼ˆ5æ—¥å‰æ¯”+ï¼‰ã‚’åŠ ç‚¹", value=True)

st.sidebar.subheader("ğŸ§ª å®Ÿè¡Œè¨­å®š")
batch_size = st.sidebar.slider("ãƒãƒƒãƒã‚µã‚¤ã‚ºï¼ˆyfinanceä¸€æ‹¬å–å¾—ï¼‰", 10, 100, 50, 5)
use_auto_adjust = st.sidebar.checkbox("ä¾¡æ ¼ã‚’èª¿æ•´ï¼ˆauto_adjust=Trueï¼‰", value=True)

scan_period = st.sidebar.selectbox("ã‚¹ã‚­ãƒ£ãƒ³ç”¨ å–å¾—æœŸé–“ï¼ˆæŒ‡æ¨™ã«å¿…è¦ï¼‰", ["3mo", "6mo", "1y"], index=1)
top_k = st.sidebar.slider("è¡¨ç¤ºä»¶æ•°ï¼ˆä¸Šä½ï¼‰", 10, 200, 50, 5)

if st.sidebar.button("ğŸ”„ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢"):
    st.cache_data.clear()
    st.rerun()

# =========================
# 3. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
# =========================
@st.cache_data(ttl=3600)
def load_master_data(market_name: str) -> Tuple[List[str], Dict[str, str]]:
    with urllib.request.urlopen(GITHUB_CSV_URL) as resp:
        df = pd.read_csv(BytesIO(resp.read()))

    m_key = f"{market_name}ï¼ˆå†…å›½æ ªå¼ï¼‰"
    df_filtered = df[(df["å¸‚å ´ãƒ»å•†å“åŒºåˆ†"] == m_key) & (df["33æ¥­ç¨®åŒºåˆ†"] != "ï¼")].copy()

    tickers = [f"{str(code).split('.')[0]}.T" for code in df_filtered["ã‚³ãƒ¼ãƒ‰"]]
    info = {f"{str(row['ã‚³ãƒ¼ãƒ‰']).split('.')[0]}.T": row["éŠ˜æŸ„å"] for _, row in df_filtered.iterrows()}
    return tickers, info


def compute_atr(df: pd.DataFrame, period: int) -> pd.Series:
    high = df["High"].astype(float)
    low = df["Low"].astype(float)
    close = df["Close"].astype(float)
    prev_close = close.shift(1)

    tr = pd.concat(
        [(high - low).abs(), (high - prev_close).abs(), (low - prev_close).abs()],
        axis=1,
    ).max(axis=1)

    return tr.rolling(period).mean()


def safe_float(x) -> float:
    try:
        v = float(x)
        if not np.isfinite(v):
            return np.nan
        return v
    except Exception:
        return np.nan


def calc_metrics(data: pd.DataFrame, *, jump_days_: int) -> Dict[str, float]:
    """
    æŒ‡æ¨™è¨ˆç®—ï¼ˆæœ€å¾Œã®1æ—¥åˆ†ï¼‰
    """
    c = data["Close"].astype(float)
    v = data["Volume"].astype(float)

    # æµå‹•æ€§
    avg_val = (c * v).tail(5).mean() / 1e8

    # ç¬¬ä¸€æ³¢ï¼ˆéå»40æ—¥ã§æœ€å¤§Næ—¥ä¸Šæ˜‡ç‡ï¼‰
    jump_series = (c / c.shift(jump_days_) - 1.0) * 100.0
    max_jump = jump_series.tail(40).max()

    # æ¯æ¸‡ï¼ˆä¸­å¤®å€¤ï¼‰
    v_med20 = v.tail(20).median()
    rvol_med = (v.iloc[-1] / v_med20) if v_med20 > 0 else np.nan

    # 25MAä¹–é›¢
    ma25 = c.rolling(25).mean().iloc[-1]
    curr_p = c.iloc[-1]
    diff_ma25 = abs(curr_p - ma25) / ma25 * 100.0 if ma25 and ma25 > 0 else np.nan

    # ATRåç¸®
    atr5 = compute_atr(data, 5).iloc[-1]
    atr20 = compute_atr(data, 20).iloc[-1]
    atr_ratio = (atr5 / atr20) if atr20 and atr20 > 0 else np.nan

    # é«˜å€¤è·é›¢ï¼ˆ20æ—¥ï¼‰
    high20 = c.tail(20).max()
    dist_to_high = (high20 - curr_p) / curr_p * 100.0 if curr_p and curr_p > 0 else np.nan

    # MAå‘ã
    ma25_now = c.rolling(25).mean().iloc[-1]
    ma25_prev = c.rolling(25).mean().shift(5).iloc[-1]
    ma25_slope = ma25_now - ma25_prev

    return {
        "price": safe_float(curr_p),
        "avg_val": safe_float(avg_val),
        "max_jump": safe_float(max_jump),
        "rvol": safe_float(rvol_med),
        "diff_ma25": safe_float(diff_ma25),
        "atr_ratio": safe_float(atr_ratio),
        "dist_to_high": safe_float(dist_to_high),
        "ma25_slope": safe_float(ma25_slope),
    }


def pass_filter(m: Dict[str, float], *, min_avg_value_: float, vol_dry_limit_: float, ma_near_pct_: float) -> bool:
    """
    è¶³åˆ‡ã‚Šã¯3ã¤ã ã‘ï¼ˆ0ä»¶å•é¡Œã‚’æ½°ã™ãŸã‚ï¼‰
    """
    if not np.isfinite(m.get("avg_val", np.nan)) or m["avg_val"] < min_avg_value_:
        return False
    if not np.isfinite(m.get("rvol", np.nan)) or m["rvol"] > vol_dry_limit_:
        return False
    if not np.isfinite(m.get("diff_ma25", np.nan)) or m["diff_ma25"] > ma_near_pct_:
        return False
    return True


def score_metrics(
    m: Dict[str, float],
    *,
    min_jump_: float,
    atr_contract_limit_: float,
    dist_to_high_limit_: float,
    require_ma_up_: bool,
) -> float:
    """
    è½ã¨ã•ãšé †ä½ä»˜ã‘ã«ä½¿ã†ã‚¹ã‚³ã‚¢
    - ç¬¬ä¸€æ³¢ãŒå¼·ã„ã»ã©â†‘
    - æ¯æ¸‡ï¼ˆrvolï¼‰ãŒå°ã•ã„ã»ã©â†‘
    - ATRåç¸®ï¼ˆatr_ratioï¼‰ãŒå°ã•ã„ã»ã©â†‘
    - é«˜å€¤ãŒè¿‘ã„ã»ã©â†‘
    - MAãŒä¸Šå‘ããªã‚‰ãƒœãƒ¼ãƒŠã‚¹
    """
    max_jump = m.get("max_jump", np.nan)
    rvol = m.get("rvol", np.nan)
    atr_ratio = m.get("atr_ratio", np.nan)
    dist = m.get("dist_to_high", np.nan)
    diff = m.get("diff_ma25", np.nan)
    slope = m.get("ma25_slope", 0.0)

    # æ¬ æã¯å¼±ã‚è©•ä¾¡
    max_jump = 0.0 if not np.isfinite(max_jump) else max(0.0, min(max_jump, 200.0))
    rvol = 9.9 if not np.isfinite(rvol) else max(0.05, min(rvol, 9.9))
    atr_ratio = 9.9 if not np.isfinite(atr_ratio) else max(0.20, min(atr_ratio, 9.9))
    dist = 99.0 if not np.isfinite(dist) else max(0.0, min(dist, 99.0))
    diff = 99.0 if not np.isfinite(diff) else max(0.0, min(diff, 99.0))

    # åŠ ç‚¹ï¼šç¬¬ä¸€æ³¢ï¼ˆmin_jumpã‚’åŸºæº–ã«ã€Œè¶…ãˆãŸåº¦åˆã„ã€ï¼‰
    # ä¾‹: min_jump=15ãªã‚‰ã€15%è¶…ãˆã‹ã‚‰åŠ¹ã
    s_jump = max(0.0, (max_jump - min_jump_) / 50.0)  # ã ã„ãŸã„0ã€œ2
    s_rvol = 1.0 / rvol                               # æ¯æ¸‡ã»ã©å¼·ã„
    s_atr = 1.0 / atr_ratio                           # åç¸®ã»ã©å¼·ã„
    s_dist = 1.0 / (1.0 + max(0.0, dist - dist_to_high_limit_))  # é«˜å€¤ãŒé ã„ã»ã©æ¸›ç‚¹
    s_diff = 1.0 / (1.0 + diff)                       # MAã‹ã‚‰é›¢ã‚Œã‚‹ã»ã©æ¸›ç‚¹
    s_ma = 0.25 if (require_ma_up_ and slope > 0) else 0.0

    # ç›´æ„Ÿã«å¯„ã›ãŸé‡ã¿
    return (
        1.40 * s_jump +
        1.10 * s_rvol +
        1.00 * s_atr +
        0.80 * s_dist +
        0.60 * s_diff +
        s_ma
    )


# =========================
# 4. ãƒ¡ã‚¤ãƒ³ç”»é¢
# =========================
st.title(f"ğŸš€ {target_market}ãƒ»äºŒæ®µä¸Šã’ç‹™ã„ï¼ˆå®Ÿç”¨ç‰ˆï¼‰")
st.caption("0ä»¶å•é¡Œã‚’æ½°ã—ã¦ã€Œæ¯æ—¥ä½¿ãˆã‚‹å€™è£œãƒªã‚¹ãƒˆã€ã«å¯„ã›ãŸç‰ˆã€‚è¶³åˆ‡ã‚Šã¯3ã¤ã ã‘ã€ã‚ã¨ã¯ã‚¹ã‚³ã‚¢ã§ä¸¦ã¹ã‚‹ã€‚")

colA, colB = st.columns([1.2, 1.8])
with colA:
    st.write("**è¶³åˆ‡ã‚Šï¼ˆå¿…é ˆï¼‰**")
    st.write(f"- å£²è²·ä»£é‡‘(5æ—¥å¹³å‡) â‰¥ {min_avg_value:.2f} å„„å††")
    st.write(f"- æ¯æ¸‡RVOL(å½“æ—¥/20æ—¥ä¸­å¤®å€¤) â‰¤ {vol_dry_limit:.2f}")
    st.write(f"- 25MAä¹–é›¢ â‰¤ {ma_near_pct:.1f}%")

with colB:
    st.write("**ã‚¹ã‚³ã‚¢åŠ ç‚¹ï¼ˆé †ä½ä»˜ã‘ï¼‰**")
    st.write(f"- ç¬¬ä¸€æ³¢: {jump_days}æ—¥ä¸Šæ˜‡ï¼ˆéå»40æ—¥maxï¼‰ / ç›®å®‰ {min_jump:.0f}%")
    st.write(f"- ATRåç¸®ç›®å®‰: ATR5/ATR20 â‰¤ {atr_contract_limit:.2f}")
    st.write(f"- é«˜å€¤è·é›¢ç›®å®‰: 20æ—¥é«˜å€¤ã¾ã§ â‰¤ {dist_to_high_limit:.1f}%")
    st.write(f"- MAä¸Šå‘ãåŠ ç‚¹: {'ON' if require_ma_up else 'OFF'}")

if st.button("ğŸ“¡ ã‚¹ã‚­ãƒ£ãƒ³é–‹å§‹", type="primary"):
    tickers, info_db = load_master_data(target_market)
    if not tickers:
        st.warning("å¯¾è±¡éŠ˜æŸ„ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        st.stop()

    strict_results: List[Dict[str, object]] = []
    all_candidates: List[Dict[str, object]] = []
    fail_counts = {"å£²è²·ä»£é‡‘": 0, "æ¯æ¸‡": 0, "25MAä¹–é›¢": 0, "ãƒ‡ãƒ¼ã‚¿ä¸è¶³": 0, "å–å¾—å¤±æ•—": 0}

    progress_bar = st.progress(0)
    status_text = st.empty()

    total = len(tickers)
    t0 = time.time()

    for i in range(0, total, batch_size):
        batch = tickers[i: i + batch_size]
        status_text.text(f"ã‚¹ã‚­ãƒ£ãƒ³ä¸­... {i}/{total}")
        progress_bar.progress(min(1.0, i / total))

        try:
            df_batch = yf.download(
                batch,
                period=scan_period,
                interval="1d",
                progress=False,
                group_by="ticker",
                threads=True,
                auto_adjust=use_auto_adjust,
            )
            if df_batch is None or df_batch.empty:
                fail_counts["å–å¾—å¤±æ•—"] += len(batch)
                continue

            if not isinstance(df_batch.columns, pd.MultiIndex):
                # 1éŠ˜æŸ„ã ã‘ã®ã¨ã
                df_batch = pd.concat({batch[0]: df_batch}, axis=1)

            tickers_in_batch = set(df_batch.columns.get_level_values(0))

            for t in batch:
                if t not in tickers_in_batch:
                    fail_counts["å–å¾—å¤±æ•—"] += 1
                    continue

                stock_data = df_batch[t].dropna()
                need_cols = {"Open", "High", "Low", "Close", "Volume"}
                if stock_data.empty or not need_cols.issubset(set(stock_data.columns)):
                    fail_counts["å–å¾—å¤±æ•—"] += 1
                    continue

                # æŒ‡æ¨™è¨ˆç®—ã«å¿…è¦ãªé•·ã•
                if len(stock_data) < 80:
                    fail_counts["ãƒ‡ãƒ¼ã‚¿ä¸è¶³"] += 1
                    continue

                m = calc_metrics(stock_data, jump_days_=jump_days)

                # è¶³åˆ‡ã‚Šå¤±æ•—å†…è¨³ï¼ˆãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ï¼‰
                if not (np.isfinite(m["avg_val"]) and m["avg_val"] >= min_avg_value):
                    fail_counts["å£²è²·ä»£é‡‘"] += 1
                elif not (np.isfinite(m["rvol"]) and m["rvol"] <= vol_dry_limit):
                    fail_counts["æ¯æ¸‡"] += 1
                elif not (np.isfinite(m["diff_ma25"]) and m["diff_ma25"] <= ma_near_pct):
                    fail_counts["25MAä¹–é›¢"] += 1

                sc = score_metrics(
                    m,
                    min_jump_=min_jump,
                    atr_contract_limit_=atr_contract_limit,
                    dist_to_high_limit_=dist_to_high_limit,
                    require_ma_up_=require_ma_up,
                )

                row = {
                    "ticker": t,
                    "ã‚³ãƒ¼ãƒ‰": t.replace(".T", ""),
                    "éŠ˜æŸ„å": info_db.get(t, "ä¸æ˜"),
                    "ã‚¹ã‚³ã‚¢": float(sc),
                    "ç¾åœ¨å€¤": float(m["price"]) if np.isfinite(m["price"]) else np.nan,
                    f"ç¬¬ä¸€æ³¢({jump_days}æ—¥)%": float(m["max_jump"]) if np.isfinite(m["max_jump"]) else np.nan,
                    "æ¯æ¸‡RVOL(ä¸­å¤®å€¤)": float(m["rvol"]) if np.isfinite(m["rvol"]) else np.nan,
                    "25MAä¹–é›¢%": float(m["diff_ma25"]) if np.isfinite(m["diff_ma25"]) else np.nan,
                    "ATR5/20": float(m["atr_ratio"]) if np.isfinite(m["atr_ratio"]) else np.nan,
                    "é«˜å€¤è·é›¢%": float(m["dist_to_high"]) if np.isfinite(m["dist_to_high"]) else np.nan,
                    "ä»£é‡‘(å„„å††)": float(m["avg_val"]) if np.isfinite(m["avg_val"]) else np.nan,
                    "MAå‚¾ã(å‚è€ƒ)": float(m["ma25_slope"]) if np.isfinite(m["ma25_slope"]) else np.nan,
                }
                all_candidates.append(row)

                if pass_filter(m, min_avg_value_=min_avg_value, vol_dry_limit_=vol_dry_limit, ma_near_pct_=ma_near_pct):
                    strict_results.append(row)

        except Exception:
            fail_counts["å–å¾—å¤±æ•—"] += len(batch)
            continue

    progress_bar.progress(1.0)
    status_text.empty()
    elapsed = time.time() - t0

    # ã‚µãƒãƒªãƒ¼
    st.subheader("çµæœã‚µãƒãƒªãƒ¼")
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("ãƒ’ãƒƒãƒˆéŠ˜æŸ„æ•°ï¼ˆè¶³åˆ‡ã‚Šé€šéï¼‰", f"{len(strict_results)}")
    c2.metric("å¯¾è±¡éŠ˜æŸ„æ•°", f"{total}")
    c3.metric("å‡¦ç†æ™‚é–“(ç§’)", f"{elapsed:.1f}")
    c4.metric("å–å¾—å¤±æ•—ï¼ˆæ¦‚ç®—ï¼‰", f"{fail_counts['å–å¾—å¤±æ•—']}")

    with st.expander("è½é¸å†…è¨³ï¼ˆè¶³åˆ‡ã‚Š3æ¡ä»¶ï¼‰", expanded=False):
        st.write(pd.DataFrame([{"ç†ç”±": k, "ä»¶æ•°": v} for k, v in fail_counts.items()]))

    # è¡¨ç¤ºãƒ‡ãƒ¼ã‚¿ä½œæˆ
    def format_table(df: pd.DataFrame) -> pd.DataFrame:
        out = df.copy()
        out["ã‚¹ã‚³ã‚¢"] = out["ã‚¹ã‚³ã‚¢"].map(lambda x: f"{x:.3f}")
        out["ç¾åœ¨å€¤"] = out["ç¾åœ¨å€¤"].map(lambda x: "-" if pd.isna(x) else f"{x:,.1f}")
        out[f"ç¬¬ä¸€æ³¢({jump_days}æ—¥)%"] = out[f"ç¬¬ä¸€æ³¢({jump_days}æ—¥)%"].map(lambda x: "-" if pd.isna(x) else f"{x:.1f}%")
        out["æ¯æ¸‡RVOL(ä¸­å¤®å€¤)"] = out["æ¯æ¸‡RVOL(ä¸­å¤®å€¤)"].map(lambda x: "-" if pd.isna(x) else f"{x:.2f}å€")
        out["25MAä¹–é›¢%"] = out["25MAä¹–é›¢%"].map(lambda x: "-" if pd.isna(x) else f"{x:.1f}%")
        out["ATR5/20"] = out["ATR5/20"].map(lambda x: "-" if pd.isna(x) else f"{x:.2f}")
        out["é«˜å€¤è·é›¢%"] = out["é«˜å€¤è·é›¢%"].map(lambda x: "-" if pd.isna(x) else f"{x:.1f}%")
        out["ä»£é‡‘(å„„å††)"] = out["ä»£é‡‘(å„„å††)"].map(lambda x: "-" if pd.isna(x) else f"{x:.2f}å„„å††")
        out["MAå‚¾ã(å‚è€ƒ)"] = out["MAå‚¾ã(å‚è€ƒ)"].map(lambda x: "-" if pd.isna(x) else f"{x:.2f}")
        return out

    # ã¾ãšè¶³åˆ‡ã‚Šé€šéãŒã‚ã‚‹ãªã‚‰ãã‚Œã‚’ä¸Šä½è¡¨ç¤º
    if strict_results:
        st.success("âœ… è¶³åˆ‡ã‚Šé€šééŠ˜æŸ„ã‚’ã‚¹ã‚³ã‚¢é †ã§è¡¨ç¤ºï¼ˆã¾ãšã“ã“ã‚’è¦‹ã‚‹ï¼‰")
        res_df = pd.DataFrame(strict_results).sort_values("ã‚¹ã‚³ã‚¢", ascending=False).head(top_k).reset_index(drop=True)
        show_df = format_table(res_df.drop(columns=["ticker"]))
        st.dataframe(show_df, use_container_width=True, hide_index=True)
        candidate_df = res_df
    else:
        # 0ä»¶ã®ã¨ãï¼šè‡ªå‹•ã§ç·©ã‚ã¦å€™è£œã‚’å‡ºã™ï¼ˆåŒã˜å–å¾—ãƒ‡ãƒ¼ã‚¿ã®ã¾ã¾ï¼‰
        st.warning("âš ï¸ è¶³åˆ‡ã‚Šé€šéãŒ0ä»¶ã€‚è‡ªå‹•çš„ã«æ¡ä»¶ã‚’â€œæ®µéšçš„ã«â€ç·©ã‚ã¦å€™è£œã‚’å‡ºã—ã¾ã™ã€‚")

        if not all_candidates:
            st.error("å€™è£œç”Ÿæˆã«å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ãŒå–ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å–å¾—æœŸé–“ã‚’6mo/1yã«ã—ã¦å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
            st.stop()

        base = pd.DataFrame(all_candidates).dropna(subset=["ä»£é‡‘(å„„å††)", "æ¯æ¸‡RVOL(ä¸­å¤®å€¤)", "25MAä¹–é›¢%"], how="any").copy()
        if base.empty:
            st.error("æŒ‡æ¨™è¨ˆç®—ãŒæˆç«‹ã™ã‚‹éŠ˜æŸ„ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚å–å¾—æœŸé–“ã‚’1yã«ã—ã¦å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
            st.stop()

        # æ®µéšçš„ã«ç·©ã‚ã‚‹ï¼ˆ3æ®µï¼‰
        relax_steps = [
            (min_avg_value, vol_dry_limit, ma_near_pct, "å…ƒã®æ¡ä»¶"),
            (min_avg_value * 0.8, min(vol_dry_limit * 1.3, 2.0), min(ma_near_pct * 1.3, 15.0), "å°‘ã—ç·©ã‚"),
            (min_avg_value * 0.6, min(vol_dry_limit * 1.6, 2.0), min(ma_near_pct * 1.6, 15.0), "ã•ã‚‰ã«ç·©ã‚"),
        ]

        picked = None
        picked_label = ""
        for mv, vd, mp, label in relax_steps:
            cond = (base["ä»£é‡‘(å„„å††)"] >= mv) & (base["æ¯æ¸‡RVOL(ä¸­å¤®å€¤)"] <= vd) & (base["25MAä¹–é›¢%"] <= mp)
            df_try = base.loc[cond].copy()
            if len(df_try) >= 10:
                picked = df_try
                picked_label = f"{label}ï¼ˆå£²è²·ä»£é‡‘â‰¥{mv:.2f} / RVOLâ‰¤{vd:.2f} / ä¹–é›¢â‰¤{mp:.1f}%ï¼‰"
                break

        if picked is None:
            # ãã‚Œã§ã‚‚å°‘ãªã‘ã‚Œã°ï¼šæµå‹•æ€§ã ã‘ã¯å®ˆã£ã¦ã€ã‚¹ã‚³ã‚¢ä¸Šä½ã‚’å‡ºã™
            mv = min_avg_value * 0.6
            picked = base.loc[base["ä»£é‡‘(å„„å††)"] >= mv].copy()
            picked_label = f"æœ€çµ‚æ•‘æ¸ˆï¼ˆå£²è²·ä»£é‡‘â‰¥{mv:.2f}ã®ã¿ã§æŠ½å‡º â†’ ã‚¹ã‚³ã‚¢ä¸Šä½ï¼‰"

        st.info(f"è¡¨ç¤ºãƒ«ãƒ¼ãƒ«ï¼š{picked_label}")
        candidate_df = picked.sort_values("ã‚¹ã‚³ã‚¢", ascending=False).head(top_k).reset_index(drop=True)
        show_df = format_table(candidate_df.drop(columns=["ticker"]))
        st.dataframe(show_df, use_container_width=True, hide_index=True)

   
